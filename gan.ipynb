{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src.config import get_parser\n",
    "from src.models.discriminator import Discriminator\n",
    "from src.models.generator import Generator\n",
    "from src.models.stylist import Stylist\n",
    "from src.masked_dataset import MaskedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        \n",
    "        self.G = Generator(hparams)\n",
    "        self.D = Discriminator(hparams)\n",
    "        self.S = Stylist(hparams)\n",
    "        # Renderer requires device, create in train step\n",
    "        self.renderer = None\n",
    "     \n",
    "    def forward(self, shape, style):\n",
    "        return self.G(shape, style)\n",
    "    \n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.mse_loss(y_hat, y)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        if not self.renderer:\n",
    "            self.renderer = self.create_renderer(batch.device)\n",
    "        \n",
    "        imgs, _ = batch\n",
    "\n",
    "        # sample noise\n",
    "        z = torch.randn(imgs.shape[0], self.hparams.latent_dim)\n",
    "        z = z.type_as(imgs)\n",
    "\n",
    "        # train generator\n",
    "        if optimizer_idx == 0:\n",
    "\n",
    "            # generate images\n",
    "            self.generated_imgs = self(z)\n",
    "\n",
    "            # log sampled images\n",
    "            sample_imgs = self.generated_imgs[:6]\n",
    "            grid = torchvision.utils.make_grid(sample_imgs)\n",
    "            self.logger.experiment.add_image('generated_images', grid, 0)\n",
    "\n",
    "            # ground truth result (ie: all fake)\n",
    "            # put on GPU because we created this tensor inside training_loop\n",
    "            valid = torch.ones(imgs.size(0), 1)\n",
    "            valid = valid.type_as(imgs)\n",
    "\n",
    "            # adversarial loss is binary cross-entropy\n",
    "            g_loss = self.adversarial_loss(self.discriminator(self(z)), valid)\n",
    "            tqdm_dict = {'g_loss': g_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': g_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "            return output\n",
    "\n",
    "        # train discriminator\n",
    "        if optimizer_idx == 1:\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "\n",
    "            # how well can it label as real?\n",
    "            valid = torch.ones(imgs.size(0), 1)\n",
    "            valid = valid.type_as(imgs)\n",
    "\n",
    "            real_loss = self.adversarial_loss(self.discriminator(imgs), valid)\n",
    "\n",
    "            # how well can it label as fake?\n",
    "            fake = torch.zeros(imgs.size(0), 1)\n",
    "            fake = fake.type_as(imgs)\n",
    "\n",
    "            fake_loss = self.adversarial_loss(\n",
    "                self.discriminator(self(z).detach()), fake)\n",
    "\n",
    "            # discriminator loss is the average of these\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            tqdm_dict = {'d_loss': d_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': d_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "            return output\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        b1 = self.hparams.b1\n",
    "        b2 = self.hparams.b2        \n",
    "        opt_gs = torch.optim.Adam(list(self.G.parameters()) \n",
    "                                 + list(self.S.parameters()), \n",
    "                                 lr=lr, betas=(b1, b2))\n",
    "        opt_d = torch.optim.Adam(self.D.parameters(), \n",
    "                                 lr=lr, betas=(b1, b2))\n",
    "        return [opt_gs, opt_d], []\n",
    "    \n",
    "    def create_renderer(self, device):\n",
    "        # Select the viewpoint using spherical angles\n",
    "        distance = 2 # Distance from camera to the objectlights = PointLights(device=device, location=[[0.0, -1.0, 3.0]])\n",
    "        elevation = 0. # angle of elevation in degrees\n",
    "        azimuth = 0.0 # No rotation so the camera is positioned on the +Z axis\n",
    "        viewpoint = Namespace(distance=distance, \n",
    "                              elevation=elevation, \n",
    "                              azimuth=azimuth)\n",
    "\n",
    "        lights = Namespace(location=[[0.0, -1.0, 3.0]])\n",
    "\n",
    "        raster = Namespace(image_size=512, \n",
    "                           radius=0.006,\n",
    "                           points_per_pixel=4)\n",
    "        return Renderer(device, viewpoint, lights, raster)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_0.3",
   "language": "python",
   "name": "pytorch3d_0.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
