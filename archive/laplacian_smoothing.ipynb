{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates. All rights reserved.\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def mesh_laplacian_smoothing(meshes, method: str = \"uniform\"):\n",
    "    r\"\"\"\n",
    "    Computes the laplacian smoothing objective for a batch of meshes.\n",
    "    This function supports three variants of Laplacian smoothing,\n",
    "    namely with uniform weights(\"uniform\"), with cotangent weights (\"cot\"),\n",
    "    and cotangent curvature (\"cotcurv\").For more details read [1, 2].\n",
    "\n",
    "    Args:\n",
    "        meshes: Meshes object with a batch of meshes.\n",
    "        method: str specifying the method for the laplacian.\n",
    "    Returns:\n",
    "        loss: Average laplacian smoothing loss across the batch.\n",
    "        Returns 0 if meshes contains no meshes or all empty meshes.\n",
    "\n",
    "    Consider a mesh M = (V, F), with verts of shape Nx3 and faces of shape Mx3.\n",
    "    The Laplacian matrix L is a NxN tensor such that LV gives a tensor of vectors:\n",
    "    for a uniform Laplacian, LuV[i] points to the centroid of its neighboring\n",
    "    vertices, a cotangent Laplacian LcV[i] is known to be an approximation of\n",
    "    the surface normal, while the curvature variant LckV[i] scales the normals\n",
    "    by the discrete mean curvature. For vertex i, assume S[i] is the set of\n",
    "    neighboring vertices to i, a_ij and b_ij are the \"outside\" angles in the\n",
    "    two triangles connecting vertex v_i and its neighboring vertex v_j\n",
    "    for j in S[i], as seen in the diagram below.\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "               a_ij\n",
    "                /\\\n",
    "               /  \\\n",
    "              /    \\\n",
    "             /      \\\n",
    "        v_i /________\\ v_j\n",
    "            \\        /\n",
    "             \\      /\n",
    "              \\    /\n",
    "               \\  /\n",
    "                \\/\n",
    "               b_ij\n",
    "\n",
    "        The definition of the Laplacian is LV[i] = sum_j w_ij (v_j - v_i)\n",
    "        For the uniform variant,    w_ij = 1 / |S[i]|\n",
    "        For the cotangent variant,\n",
    "            w_ij = (cot a_ij + cot b_ij) / (sum_k cot a_ik + cot b_ik)\n",
    "        For the cotangent curvature, w_ij = (cot a_ij + cot b_ij) / (4 A[i])\n",
    "        where A[i] is the sum of the areas of all triangles containing vertex v_i.\n",
    "\n",
    "    There is a nice trigonometry identity to compute cotangents. Consider a triangle\n",
    "    with side lengths A, B, C and angles a, b, c.\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "               c\n",
    "              /|\\\n",
    "             / | \\\n",
    "            /  |  \\\n",
    "         B /  H|   \\ A\n",
    "          /    |    \\\n",
    "         /     |     \\\n",
    "        /a_____|_____b\\\n",
    "               C\n",
    "\n",
    "        Then cot a = (B^2 + C^2 - A^2) / 4 * area\n",
    "        We know that area = CH/2, and by the law of cosines we have\n",
    "\n",
    "        A^2 = B^2 + C^2 - 2BC cos a => B^2 + C^2 - A^2 = 2BC cos a\n",
    "\n",
    "        Putting these together, we get:\n",
    "\n",
    "        B^2 + C^2 - A^2     2BC cos a\n",
    "        _______________  =  _________ = (B/H) cos a = cos a / sin a = cot a\n",
    "           4 * area            2CH\n",
    "\n",
    "\n",
    "    [1] Desbrun et al, \"Implicit fairing of irregular meshes using diffusion\n",
    "    and curvature flow\", SIGGRAPH 1999.\n",
    "\n",
    "    [2] Nealan et al, \"Laplacian Mesh Optimization\", Graphite 2006.\n",
    "    \"\"\"\n",
    "\n",
    "    if meshes.isempty():\n",
    "        return torch.tensor(\n",
    "            [0.0], dtype=torch.float32, device=meshes.device, requires_grad=True\n",
    "        )\n",
    "\n",
    "    N = len(meshes)\n",
    "    verts_packed = meshes.verts_packed()  # (sum(V_n), 3)\n",
    "    num_verts_per_mesh = meshes.num_verts_per_mesh()  # (N,)\n",
    "    verts_packed_idx = meshes.verts_packed_to_mesh_idx()  # (sum(V_n),)\n",
    "    weights = num_verts_per_mesh.gather(0, verts_packed_idx)  # (sum(V_n),)\n",
    "    weights = 1.0 / weights.float()\n",
    "\n",
    "    # We don't want to backprop through the computation of the Laplacian;\n",
    "    # just treat it as a magic constant matrix that is used to transform\n",
    "    # verts into normals\n",
    "    with torch.no_grad():\n",
    "        if method == \"uniform\":\n",
    "            L = meshes.laplacian_packed()\n",
    "        elif method in [\"cot\", \"cotcurv\"]:\n",
    "            L, inv_areas = laplacian_cot(meshes)\n",
    "            if method == \"cot\":\n",
    "                norm_w = torch.sparse.sum(L, dim=1).to_dense().view(-1, 1)\n",
    "                idx = norm_w > 0\n",
    "                norm_w[idx] = 1.0 / norm_w[idx]\n",
    "            else:\n",
    "                L_sum = torch.sparse.sum(L, dim=1).to_dense().view(-1, 1)\n",
    "                norm_w = 0.25 * inv_areas\n",
    "        else:\n",
    "            raise ValueError(\"Method should be one of {uniform, cot, cotcurv}\")\n",
    "\n",
    "    if method == \"uniform\":\n",
    "        loss = L.mm(verts_packed)\n",
    "    elif method == \"cot\":\n",
    "        loss = L.mm(verts_packed) * norm_w - verts_packed\n",
    "    elif method == \"cotcurv\":\n",
    "        loss = (L.mm(verts_packed) - L_sum * verts_packed) * norm_w\n",
    "    loss = loss.norm(dim=1)\n",
    "\n",
    "    loss = loss * weights\n",
    "    return loss.sum() / N\n",
    "\n",
    "\n",
    "\n",
    "def laplacian_cot(meshes):\n",
    "    \"\"\"\n",
    "    Returns the Laplacian matrix with cotangent weights and the inverse of the\n",
    "    face areas.\n",
    "\n",
    "    Args:\n",
    "        meshes: Meshes object with a batch of meshes.\n",
    "    Returns:\n",
    "        2-element tuple containing\n",
    "        - **L**: FloatTensor of shape (V,V) for the Laplacian matrix (V = sum(V_n))\n",
    "           Here, L[i, j] = cot a_ij + cot b_ij iff (i, j) is an edge in meshes.\n",
    "           See the description above for more clarity.\n",
    "        - **inv_areas**: FloatTensor of shape (V,) containing the inverse of sum of\n",
    "           face areas containing each vertex\n",
    "    \"\"\"\n",
    "    verts_packed = meshes.verts_packed()  # (sum(V_n), 3)\n",
    "    faces_packed = meshes.faces_packed()  # (sum(F_n), 3)\n",
    "    # V = sum(V_n), F = sum(F_n)\n",
    "    V, F = verts_packed.shape[0], faces_packed.shape[0]\n",
    "\n",
    "    face_verts = verts_packed[faces_packed]\n",
    "    v0, v1, v2 = face_verts[:, 0], face_verts[:, 1], face_verts[:, 2]\n",
    "\n",
    "    # Side lengths of each triangle, of shape (sum(F_n),)\n",
    "    # A is the side opposite v1, B is opposite v2, and C is opposite v3\n",
    "    A = (v1 - v2).norm(dim=1)\n",
    "    B = (v0 - v2).norm(dim=1)\n",
    "    C = (v0 - v1).norm(dim=1)\n",
    "\n",
    "    # Area of each triangle (with Heron's formula); shape is (sum(F_n),)\n",
    "    s = 0.5 * (A + B + C)\n",
    "    # note that the area can be negative (close to 0) causing nans after sqrt()\n",
    "    # we clip it to a small positive value\n",
    "    area = (s * (s - A) * (s - B) * (s - C)).clamp_(min=1e-12).sqrt()\n",
    "\n",
    "    # Compute cotangents of angles, of shape (sum(F_n), 3)\n",
    "    A2, B2, C2 = A * A, B * B, C * C\n",
    "    cota = (B2 + C2 - A2) / area\n",
    "    cotb = (A2 + C2 - B2) / area\n",
    "    cotc = (A2 + B2 - C2) / area\n",
    "    cot = torch.stack([cota, cotb, cotc], dim=1)\n",
    "    cot /= 4.0\n",
    "\n",
    "    # Construct a sparse matrix by basically doing:\n",
    "    # L[v1, v2] = cota\n",
    "    # L[v2, v0] = cotb\n",
    "    # L[v0, v1] = cotc\n",
    "    ii = faces_packed[:, [1, 2, 0]]\n",
    "    jj = faces_packed[:, [2, 0, 1]]\n",
    "    idx = torch.stack([ii, jj], dim=0).view(2, F * 3)\n",
    "    L = torch.sparse.FloatTensor(idx, cot.view(-1), (V, V))\n",
    "\n",
    "    # Make it symmetric; this means we are also setting\n",
    "    # L[v2, v1] = cota\n",
    "    # L[v0, v2] = cotb\n",
    "    # L[v1, v0] = cotc\n",
    "    L += L.t()\n",
    "\n",
    "    # For each vertex, compute the sum of areas for triangles containing it.\n",
    "    idx = faces_packed.view(-1)\n",
    "    inv_areas = torch.zeros(V, dtype=torch.float32, device=meshes.device)\n",
    "    val = torch.stack([area] * 3, dim=1).view(-1)\n",
    "    inv_areas.scatter_add_(0, idx, val)\n",
    "    idx = inv_areas > 0\n",
    "    inv_areas[idx] = 1.0 / inv_areas[idx]\n",
    "    inv_areas = inv_areas.view(-1, 1)\n",
    "\n",
    "    return L, inv_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pytorch3d.structures.meshes.Meshes at 0x7fee256e1cd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from src.config import get_parser\n",
    "from src.util import make_faces\n",
    "from pytorch3d.structures import Meshes\n",
    "\n",
    "config = get_parser().parse_args(args=[])\n",
    "\n",
    "blueprint = np.load(os.path.join(config.data_dir, config.blueprint)) \n",
    "points = torch.tensor(blueprint['points'])\n",
    "normals = torch.tensor(blueprint['normals'])\n",
    "points = F.interpolate(points, size=config.data_blueprint_size,\n",
    "                               mode='bicubic', align_corners=True)\n",
    "normals = F.interpolate(normals, size=config.data_blueprint_size, \n",
    "                        mode='bicubic', align_corners=True)   \n",
    "points.shape, normals.shape\n",
    "\n",
    "faces = torch.tensor(make_faces(config.data_blueprint_size, config.data_blueprint_size))\n",
    "faces.shape\n",
    "\n",
    "bs = 5\n",
    "verts = points.reshape(1, 3, -1).permute(0, 2, 1).expand(bs, -1, -1)\n",
    "face_id = faces[None].expand(bs, -1, -1)\n",
    "verts.shape, face_id.shape\n",
    "\n",
    "trg_mesh = Meshes(verts=verts, faces=face_id)\n",
    "trg_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[      0,       0,       0,  ..., 2047998, 2047999,\n",
       "                        2047999],\n",
       "                       [      0,       1,     640,  ..., 2047997, 2047998,\n",
       "                        2047999]]),\n",
       "       values=tensor([-1.0000,  0.5000,  0.5000,  ...,  0.2500,  0.5000,\n",
       "                      -1.0000]),\n",
       "       size=(2048000, 2048000), nnz=14310410, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We don't want to backprop through the computation of the Laplacian;\n",
    "# just treat it as a magic constant matrix that is used to transform\n",
    "# verts into normals\n",
    "# with torch.no_grad():\n",
    "#     if method == \"uniform\":\n",
    "#         L = meshes.laplacian_packed()\n",
    "#     elif method in [\"cot\", \"cotcurv\"]:\n",
    "#         L, inv_areas = laplacian_cot(meshes)\n",
    "#         if method == \"cot\":\n",
    "#             norm_w = torch.sparse.sum(L, dim=1).to_dense().view(-1, 1)\n",
    "#             idx = norm_w > 0\n",
    "#             norm_w[idx] = 1.0 / norm_w[idx]\n",
    "#         else:\n",
    "#             L_sum = torch.sparse.sum(L, dim=1).to_dense().view(-1, 1)\n",
    "#             norm_w = 0.25 * inv_areas\n",
    "#     else:\n",
    "#         raise ValueError(\"Method should be one of {uniform, cot, cotcurv}\")\n",
    "\n",
    "# if method == \"uniform\":\n",
    "#     loss = L.mm(verts_packed)\n",
    "# elif method == \"cot\":\n",
    "#     loss = L.mm(verts_packed) * norm_w - verts_packed\n",
    "# elif method == \"cotcurv\":\n",
    "#     loss = (L.mm(verts_packed) - L_sum * verts_packed) * norm_w\n",
    "# loss = loss.norm(dim=1)\n",
    "meshes = trg_mesh\n",
    "L = meshes.laplacian_packed()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048000, 2048000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 1, 1],\n",
       "                       [2, 0, 2]]),\n",
       "       values=tensor([3, 4, 5]),\n",
       "       size=(2, 3), nnz=3, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = [[0, 1, 1],\n",
    "         [2, 0, 2]]\n",
    "v =  [3, 4, 5]\n",
    "s = torch.sparse_coo_tensor(i, v, (2, 3))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_laplacian_packed(self, refresh: bool = False):\n",
    "    \"\"\"\n",
    "    Computes the laplacian in packed form.\n",
    "    The definition of the laplacian is\n",
    "    L[i, j] =    -1       , if i == j\n",
    "    L[i, j] = 1 / deg(i)  , if (i, j) is an edge\n",
    "    L[i, j] =    0        , otherwise\n",
    "    where deg(i) is the degree of the i-th vertex in the graph\n",
    "\n",
    "    Returns:\n",
    "        Sparse FloatTensor of shape (V, V) where V = sum(V_n)\n",
    "\n",
    "    \"\"\"\n",
    "    if not (refresh or self._laplacian_packed is None):\n",
    "        return\n",
    "\n",
    "    if self.isempty():\n",
    "        self._laplacian_packed = torch.zeros(\n",
    "            (0, 0), dtype=torch.float32, device=self.device\n",
    "        ).to_sparse()\n",
    "        return\n",
    "\n",
    "    verts_packed = self.verts_packed()  # (sum(V_n), 3)\n",
    "    edges_packed = self.edges_packed()  # (sum(E_n), 3)\n",
    "    V = verts_packed.shape[0]  # sum(V_n)\n",
    "\n",
    "    e0, e1 = edges_packed.unbind(1)\n",
    "\n",
    "    idx01 = torch.stack([e0, e1], dim=1)  # (sum(E_n), 2)\n",
    "    idx10 = torch.stack([e1, e0], dim=1)  # (sum(E_n), 2)\n",
    "    idx = torch.cat([idx01, idx10], dim=0).t()  # (2, 2*sum(E_n))\n",
    "\n",
    "    # First, we construct the adjacency matrix,\n",
    "    # i.e. A[i, j] = 1 if (i,j) is an edge, or\n",
    "    # A[e0, e1] = 1 &  A[e1, e0] = 1\n",
    "    ones = torch.ones(idx.shape[1], dtype=torch.float32, device=self.device)\n",
    "    A = torch.sparse.FloatTensor(idx, ones, (V, V))\n",
    "\n",
    "    # the sum of i-th row of A gives the degree of the i-th vertex\n",
    "    deg = torch.sparse.sum(A, dim=1).to_dense()\n",
    "\n",
    "    # We construct the Laplacian matrix by adding the non diagonal values\n",
    "    # i.e. L[i, j] = 1 ./ deg(i) if (i, j) is an edge\n",
    "    deg0 = deg[e0]\n",
    "    deg0 = torch.where(deg0 > 0.0, 1.0 / deg0, deg0)\n",
    "    deg1 = deg[e1]\n",
    "    deg1 = torch.where(deg1 > 0.0, 1.0 / deg1, deg1)\n",
    "    val = torch.cat([deg0, deg1])\n",
    "    L = torch.sparse.FloatTensor(idx, val, (V, V))\n",
    "\n",
    "    # Then we add the diagonal values L[i, i] = -1.\n",
    "    idx = torch.arange(V, device=self.device)\n",
    "    idx = torch.stack([idx, idx], dim=0)\n",
    "    ones = torch.ones(idx.shape[1], dtype=torch.float32, device=self.device)\n",
    "    L -= torch.sparse.FloatTensor(idx, ones, (V, V))\n",
    "\n",
    "    self._laplacian_packed = L\n",
    "    \n",
    "def _compute_laplacian_packed(self, refresh: bool = False):\n",
    "    \"\"\"\n",
    "    Computes the laplacian in packed form.\n",
    "    The definition of the laplacian is\n",
    "    L[i, j] =    -1       , if i == j\n",
    "    L[i, j] = 1 / deg(i)  , if (i, j) is an edge\n",
    "    L[i, j] =    0        , otherwise\n",
    "    where deg(i) is the degree of the i-th vertex in the graph\n",
    "\n",
    "    Returns:\n",
    "        Sparse FloatTensor of shape (V, V) where V = sum(V_n)\n",
    "\n",
    "    \"\"\"   \n",
    "    verts_packed = self.verts_packed()  # (sum(V_n), 3)\n",
    "    edges_packed = self.edges_packed()  # (sum(E_n), 3)\n",
    "    V = verts_packed.shape[0]  # sum(V_n)\n",
    "\n",
    "    e0, e1 = edges_packed.unbind(1)\n",
    "\n",
    "    idx01 = torch.stack([e0, e1], dim=1)  # (sum(E_n), 2)\n",
    "    idx10 = torch.stack([e1, e0], dim=1)  # (sum(E_n), 2)\n",
    "    idx = torch.cat([idx01, idx10], dim=0).t()  # (2, 2*sum(E_n))\n",
    "\n",
    "    # First, we construct the adjacency matrix,\n",
    "    # i.e. A[i, j] = 1 if (i,j) is an edge, or\n",
    "    # A[e0, e1] = 1 &  A[e1, e0] = 1\n",
    "    ones = torch.ones(idx.shape[1], dtype=torch.float32, device=self.device)\n",
    "    A = torch.sparse.FloatTensor(idx, ones, (V, V))\n",
    "\n",
    "    # the sum of i-th row of A gives the degree of the i-th vertex\n",
    "    deg = torch.sparse.sum(A, dim=1).to_dense()\n",
    "\n",
    "    # We construct the Laplacian matrix by adding the non diagonal values\n",
    "    # i.e. L[i, j] = 1 ./ deg(i) if (i, j) is an edge\n",
    "    deg0 = deg[e0]\n",
    "    deg0 = torch.where(deg0 > 0.0, 1.0 / deg0, deg0)\n",
    "    deg1 = deg[e1]\n",
    "    deg1 = torch.where(deg1 > 0.0, 1.0 / deg1, deg1)\n",
    "    val = torch.cat([deg0, deg1])\n",
    "    L = torch.sparse.FloatTensor(idx, val, (V, V))\n",
    "\n",
    "    # Then we add the diagonal values L[i, i] = -1.\n",
    "    idx = torch.arange(V, device=self.device)\n",
    "    idx = torch.stack([idx, idx], dim=0)\n",
    "    ones = torch.ones(idx.shape[1], dtype=torch.float32, device=self.device)\n",
    "    L -= torch.sparse.FloatTensor(idx, ones, (V, V))\n",
    "\n",
    "    self._laplacian_packed = L\n",
    "    \n",
    "self = meshes\n",
    "\n",
    "verts_packed = self.verts_packed()  # (sum(V_n), 3)\n",
    "edges_packed = self.edges_packed()  # (sum(E_n), 3)\n",
    "V = verts_packed.shape[0]  # sum(V_n)\n",
    "\n",
    "e0, e1 = edges_packed.unbind(1)\n",
    "\n",
    "idx01 = torch.stack([e0, e1], dim=1)  # (sum(E_n), 2)\n",
    "idx10 = torch.stack([e1, e0], dim=1)  # (sum(E_n), 2)\n",
    "idx = torch.cat([idx01, idx10], dim=0).t()  # (2, 2*sum(E_n))\n",
    "\n",
    "# First, we construct the adjacency matrix,\n",
    "# i.e. A[i, j] = 1 if (i,j) is an edge, or\n",
    "# A[e0, e1] = 1 &  A[e1, e0] = 1\n",
    "ones = torch.ones(idx.shape[1], dtype=torch.float32, device=self.device)\n",
    "A = torch.sparse.FloatTensor(idx, ones, (V, V))\n",
    "\n",
    "# the sum of i-th row of A gives the degree of the i-th vertex\n",
    "deg = torch.sparse.sum(A, dim=1).to_dense() # Slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We construct the Laplacian matrix by adding the non diagonal values\n",
    "# i.e. L[i, j] = 1 ./ deg(i) if (i, j) is an edge\n",
    "deg0 = deg[e0]\n",
    "deg0 = torch.where(deg0 > 0.0, 1.0 / deg0, deg0)\n",
    "deg1 = deg[e1]\n",
    "deg1 = torch.where(deg1 > 0.0, 1.0 / deg1, deg1)\n",
    "val = torch.cat([deg0, deg1])\n",
    "L = torch.sparse.FloatTensor(idx, val, (V, V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we add the diagonal values L[i, i] = -1.\n",
    "idx = torch.arange(V, device=self.device)\n",
    "idx = torch.stack([idx, idx], dim=0)\n",
    "ones = torch.ones(idx.shape[1], dtype=torch.float32, device=self.device)\n",
    "L -= torch.sparse.FloatTensor(idx, ones, (V, V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048000, 2048000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_0.3",
   "language": "python",
   "name": "pytorch3d_0.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
