{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from  models.guidingNet import GuidingNet\n",
    "from models.generator import Generator\n",
    "from models.discriminator import Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GuidingNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU()\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU()\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU()\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU()\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU()\n",
       "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (disc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (cont): Linear(in_features=512, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GN = GuidingNet()\n",
    "GN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Generator\n",
      "GENERATOR NF :  64\n",
      "Init ContentEncoder\n",
      "Init Decoder\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (cnt_encoder): ContentEncoder(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2dBlock(\n",
       "        (pad): ReflectionPad2d((3, 3, 3, 3))\n",
       "        (norm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (activation): ReLU(inplace=True)\n",
       "        (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "      )\n",
       "      (1): Conv2dBlock(\n",
       "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (activation): ReLU(inplace=True)\n",
       "        (conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
       "      )\n",
       "      (2): Conv2dBlock(\n",
       "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (activation): ReLU(inplace=True)\n",
       "        (conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))\n",
       "      )\n",
       "      (3): Conv2dBlock(\n",
       "        (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (norm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (activation): ReLU(inplace=True)\n",
       "        (conv): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2))\n",
       "      )\n",
       "      (4): ResBlocks(\n",
       "        (model): Sequential(\n",
       "          (0): ResBlock(\n",
       "            (model): Sequential(\n",
       "              (0): Conv2dBlock(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (norm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                (activation): ReLU(inplace=True)\n",
       "                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (1): Conv2dBlock(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (norm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): ResBlock(\n",
       "            (model): Sequential(\n",
       "              (0): Conv2dBlock(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (norm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                (activation): ReLU(inplace=True)\n",
       "                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (1): Conv2dBlock(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (norm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (model): Sequential(\n",
       "      (0): ResBlocks(\n",
       "        (model): Sequential(\n",
       "          (0): ResBlock(\n",
       "            (model): Sequential(\n",
       "              (0): Conv2dBlock(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (norm): AdaIN2d(num_features=512)\n",
       "                (activation): ReLU(inplace=True)\n",
       "                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (1): Conv2dBlock(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (norm): AdaIN2d(num_features=512)\n",
       "                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): ResBlock(\n",
       "            (model): Sequential(\n",
       "              (0): Conv2dBlock(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (norm): AdaIN2d(num_features=512)\n",
       "                (activation): ReLU(inplace=True)\n",
       "                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (1): Conv2dBlock(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (norm): AdaIN2d(num_features=512)\n",
       "                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (2): Conv2dBlock(\n",
       "        (pad): ReflectionPad2d((2, 2, 2, 2))\n",
       "        (norm): AdaIN2d(num_features=256)\n",
       "        (activation): ReLU(inplace=True)\n",
       "        (conv): Conv2d(512, 256, kernel_size=(5, 5), stride=(1, 1))\n",
       "      )\n",
       "      (3): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (4): Conv2dBlock(\n",
       "        (pad): ReflectionPad2d((2, 2, 2, 2))\n",
       "        (norm): AdaIN2d(num_features=128)\n",
       "        (activation): ReLU(inplace=True)\n",
       "        (conv): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "      )\n",
       "      (5): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (6): Conv2dBlock(\n",
       "        (pad): ReflectionPad2d((2, 2, 2, 2))\n",
       "        (norm): AdaIN2d(num_features=64)\n",
       "        (activation): ReLU(inplace=True)\n",
       "        (conv): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "      )\n",
       "      (7): Conv2dBlock(\n",
       "        (pad): ReflectionPad2d((3, 3, 3, 3))\n",
       "        (activation): Tanh()\n",
       "        (conv): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (model): Sequential(\n",
       "      (0): LinearBlock(\n",
       "        (fc): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): LinearBlock(\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): LinearBlock(\n",
       "        (fc): Linear(in_features=256, out_features=4992, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = Generator()\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContentEncoder(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2dBlock(\n",
       "      (pad): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (norm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "    )\n",
       "    (1): Conv2dBlock(\n",
       "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
       "    )\n",
       "    (2): Conv2dBlock(\n",
       "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))\n",
       "    )\n",
       "    (3): Conv2dBlock(\n",
       "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (norm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2))\n",
       "    )\n",
       "    (4): ResBlocks(\n",
       "      (model): Sequential(\n",
       "        (0): ResBlock(\n",
       "          (model): Sequential(\n",
       "            (0): Conv2dBlock(\n",
       "              (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (norm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "              (activation): ReLU(inplace=True)\n",
       "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (1): Conv2dBlock(\n",
       "              (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (norm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock(\n",
       "          (model): Sequential(\n",
       "            (0): Conv2dBlock(\n",
       "              (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (norm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "              (activation): ReLU(inplace=True)\n",
       "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (1): Conv2dBlock(\n",
       "              (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (norm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.cnt_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (model): Sequential(\n",
       "    (0): ResBlocks(\n",
       "      (model): Sequential(\n",
       "        (0): ResBlock(\n",
       "          (model): Sequential(\n",
       "            (0): Conv2dBlock(\n",
       "              (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (norm): AdaIN2d(num_features=512)\n",
       "              (activation): ReLU(inplace=True)\n",
       "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (1): Conv2dBlock(\n",
       "              (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (norm): AdaIN2d(num_features=512)\n",
       "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock(\n",
       "          (model): Sequential(\n",
       "            (0): Conv2dBlock(\n",
       "              (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (norm): AdaIN2d(num_features=512)\n",
       "              (activation): ReLU(inplace=True)\n",
       "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (1): Conv2dBlock(\n",
       "              (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (norm): AdaIN2d(num_features=512)\n",
       "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (2): Conv2dBlock(\n",
       "      (pad): ReflectionPad2d((2, 2, 2, 2))\n",
       "      (norm): AdaIN2d(num_features=256)\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(5, 5), stride=(1, 1))\n",
       "    )\n",
       "    (3): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (4): Conv2dBlock(\n",
       "      (pad): ReflectionPad2d((2, 2, 2, 2))\n",
       "      (norm): AdaIN2d(num_features=128)\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "    )\n",
       "    (5): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (6): Conv2dBlock(\n",
       "      (pad): ReflectionPad2d((2, 2, 2, 2))\n",
       "      (norm): AdaIN2d(num_features=64)\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (conv): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    )\n",
       "    (7): Conv2dBlock(\n",
       "      (pad): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (activation): Tanh()\n",
       "      (conv): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 16, 16])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.cnt_encoder(torch.rand(1, 3, 128, 128)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 128]), torch.Size([1, 10]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = GN(torch.rand(1, 3, 128, 128))\n",
    "res['cont'].shape, res['disc'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (model): Sequential(\n",
       "    (0): LinearBlock(\n",
       "      (fc): Linear(in_features=64, out_features=256, bias=True)\n",
       "      (activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): LinearBlock(\n",
       "      (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): LinearBlock(\n",
       "      (fc): Linear(in_features=256, out_features=4992, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1 x 128], m2: [64 x 256] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:41",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-59d125ec24fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cont'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/tunit/models/generator.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/tunit/models/blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 128], m2: [64 x 256] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:41"
     ]
    }
   ],
   "source": [
    "G.mlp(res['cont'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Generator\n",
      "GENERATOR NF :  64\n",
      "Init ContentEncoder\n",
      "Init Decoder\n"
     ]
    }
   ],
   "source": [
    "C = GuidingNet(64)\n",
    "G = Generator(64, 128, 4)\n",
    "x_in = torch.randn(4, 3, 64, 64)\n",
    "cont = G.cnt_encoder(x_in)\n",
    "sty = C.moco(x_in)\n",
    "x_out = G.decode(cont, sty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4480])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.mlp(sty).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1442,  0.1311,  0.1664,  ..., -0.0737,  0.0959, -0.4792]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.mlp(res['cont'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4]) torch.Size([4, 10, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "D = Discriminator(64, 10)\n",
    "x_in = torch.randn(4, 3, 64, 64)\n",
    "y_in = torch.randint(0, 10, size=(4, ))\n",
    "out, feat = D(x_in, y_in)\n",
    "print(out.shape, feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ActFirstResBlk(\n",
       "      (norm1): FRN()\n",
       "      (norm2): FRN()\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (2): ActFirstResBlk(\n",
       "      (norm1): FRN()\n",
       "      (norm2): FRN()\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv1x1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): ActFirstResBlk(\n",
       "      (norm1): FRN()\n",
       "      (norm2): FRN()\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (4): ActFirstResBlk(\n",
       "      (norm1): FRN()\n",
       "      (norm2): FRN()\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv1x1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): ActFirstResBlk(\n",
       "      (norm1): FRN()\n",
       "      (norm2): FRN()\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (6): ActFirstResBlk(\n",
       "      (norm1): FRN()\n",
       "      (norm2): FRN()\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv1x1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (7): ActFirstResBlk(\n",
       "      (norm1): FRN()\n",
       "      (norm2): FRN()\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (8): ActFirstResBlk(\n",
       "      (norm1): FRN()\n",
       "      (norm2): FRN()\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv1x1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): LeakyReLU(negative_slope=0.2)\n",
       "    (10): Conv2d(1024, 1024, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (11): LeakyReLU(negative_slope=0.2)\n",
       "    (12): Conv2d(1024, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4]) torch.Size([4, 10, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "\n",
    "import math\n",
    "\n",
    "try:\n",
    "    from models.blocks import FRN, ActFirstResBlk\n",
    "except:\n",
    "    from blocks import FRN, ActFirstResBlk\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator: (image x, domain y) -> (logit out).\"\"\"\n",
    "    def __init__(self, image_size=256, num_domains=2, max_conv_dim=1024):\n",
    "        super(Discriminator, self).__init__()\n",
    "        dim_in = 64 if image_size < 256 else 32\n",
    "        blocks = []\n",
    "        blocks += [nn.Conv2d(3, dim_in, 3, 1, 1)]\n",
    "\n",
    "        repeat_num = int(np.log2(image_size)) - 2\n",
    "        for _ in range(repeat_num):\n",
    "            dim_out = min(dim_in*2, max_conv_dim)\n",
    "            blocks += [ActFirstResBlk(dim_in, dim_in, downsample=False)]\n",
    "            blocks += [ActFirstResBlk(dim_in, dim_out, downsample=True)]\n",
    "            dim_in = dim_out\n",
    "\n",
    "        blocks += [nn.LeakyReLU(0.2)]\n",
    "        blocks += [nn.Conv2d(dim_out, dim_out, 4, 1, 0)]\n",
    "        blocks += [nn.LeakyReLU(0.2)]\n",
    "        blocks += [nn.Conv2d(dim_out, num_domains, 1, 1, 0)]\n",
    "        self.main = nn.Sequential(*blocks)\n",
    "\n",
    "        self.apply(weights_init('kaiming'))\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - x: images of shape (batch, 3, image_size, image_size).\n",
    "            - y: domain indices of shape (batch).\n",
    "        Output:\n",
    "            - out: logits of shape (batch).\n",
    "        \"\"\"\n",
    "        out = self.main(x)\n",
    "        feat = out\n",
    "        out = out.view(out.size(0), -1)                          # (batch, num_domains)\n",
    "        idx = torch.LongTensor(range(y.size(0))).to(y.device)\n",
    "        out = out[idx, y]                                         # (batch)\n",
    "        return out, feat\n",
    "\n",
    "    def _initialize_weights(self, mode='fan_in'):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=mode, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def weights_init(init_type='gaussian'):\n",
    "    def init_fun(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if (classname.find('Conv') == 0 or classname.find(\n",
    "                'Linear') == 0) and hasattr(m, 'weight'):\n",
    "            if init_type == 'gaussian':\n",
    "                init.normal_(m.weight.data, 0.0, 0.02)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=math.sqrt(2))\n",
    "            elif init_type == 'kaiming':\n",
    "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=math.sqrt(2))\n",
    "            elif init_type == 'default':\n",
    "                pass\n",
    "            else:\n",
    "                assert 0, \"Unsupported initialization: {}\".format(init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "    return init_fun\n",
    "\n",
    "D = Discriminator(64, 10)\n",
    "x_in = torch.randn(4, 3, 64, 64)\n",
    "y_in = torch.randint(0, 10, size=(4, ))\n",
    "out, feat = D(x_in, y_in)\n",
    "print(out.shape, feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7367],\n",
      "        [-0.7327],\n",
      "        [ 0.8354],\n",
      "        [-0.6063]], grad_fn=<ViewBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = out\n",
    "out = feat.view(out.size(0), -1)                          # (batch, num_domains)\n",
    "print(out)\n",
    "y = y_in\n",
    "idx = torch.LongTensor(range(y.size(0))).to(y.device)\n",
    "idx\n",
    "# out = out[idx, y]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 1, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 5, 7, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0200]],\n",
       "\n",
       "        [[ 2.1124]],\n",
       "\n",
       "        [[-2.0205]],\n",
       "\n",
       "        [[ 0.1798]]], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat[idx, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
