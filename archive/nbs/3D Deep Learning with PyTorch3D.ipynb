{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch3d\n",
    "\n",
    "from pytorch3d.structures import Meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts_list = [torch.tensor([]), torch.tensor([])]\n",
    "faces_list = [torch.tensor([]), torch.tensor([])]\n",
    "mesh_batch = Meshes(verts=verts_list, faces=faces_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh_batch.verts_packed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], dtype=torch.int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh_to_vert_idx = mesh_batch.mesh_to_verts_packed_first_idx()\n",
    "mesh_to_vert_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = mesh_batch.edges_packed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch3d.io import load_obj\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4985,  0.7125, -0.0399],\n",
       "         [-0.5017,  0.6992, -0.0638],\n",
       "         [-0.5013,  0.7178,  0.0000],\n",
       "         ...,\n",
       "         [ 0.6177,  0.2359, -0.0859],\n",
       "         [ 0.6194,  0.2831, -0.1372],\n",
       "         [ 0.6194,  0.2831,  0.1372]]),\n",
       " Faces(verts_idx=tensor([[  33, 1242,  592],\n",
       "         [  51,   26,   39],\n",
       "         [  51,   39,   64],\n",
       "         ...,\n",
       "         [ 190,  184,  168],\n",
       "         [ 189,  198,  177],\n",
       "         [ 217,  198,  189]]), normals_idx=tensor([[   0,    1,    2],\n",
       "         [   3,    4,    5],\n",
       "         [   3,    5,    6],\n",
       "         ...,\n",
       "         [ 235, 1237, 1236],\n",
       "         [1288,  207, 1286],\n",
       "         [ 213,  207, 1288]]), textures_idx=tensor([[-1, -1, -1],\n",
       "         [-1, -1, -1],\n",
       "         [-1, -1, -1],\n",
       "         ...,\n",
       "         [-1, -1, -1],\n",
       "         [-1, -1, -1],\n",
       "         [-1, -1, -1]]), materials_idx=tensor([-1, -1, -1,  ..., -1, -1, -1])),\n",
       " Properties(normals=tensor([[-0.9019,  0.4154,  0.1182],\n",
       "         [-0.9056,  0.4071,  0.1187],\n",
       "         [-0.8770,  0.4187,  0.2353],\n",
       "         ...,\n",
       "         [ 0.0558, -0.0176,  0.9983],\n",
       "         [ 0.2942, -0.8554,  0.4263],\n",
       "         [ 0.2013, -0.5409,  0.8166]]), verts_uvs=None, material_colors=None, texture_images=None, texture_atlas=None))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verts, faces, aux  = load_obj('./data/teapot.obj')\n",
    "verts, faces, aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9019,  0.4154,  0.1182],\n",
       "        [-0.9056,  0.4071,  0.1187],\n",
       "        [-0.8770,  0.4187,  0.2353],\n",
       "        ...,\n",
       "        [ 0.0558, -0.0176,  0.9983],\n",
       "        [ 0.2942, -0.8554,  0.4263],\n",
       "        [ 0.2013, -0.5409,  0.8166]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux.normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.texture_atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.texture_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.verts_uvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.material_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_mesh = pytorch3d.io.load_objs_as_meshes(['./data/teapot.obj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytorch3d.structures.meshes.Meshes at 0x7f831bc45ac0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(batched_mesh, Meshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batched_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.transforms import Transform3d, Rotate, Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example 1\n",
    "T = Translate(torch.FloatTensor([[1.0, 2.0, 3.0]]))\n",
    "R = Rotate(torch.FloatTensor([[0.0, 1.0, 0.0], \n",
    "                              [0.0, 0.0, 1.0],\n",
    "                              [1.0, 0.0, 0.0],\n",
    "                             ]))\n",
    "RT = Transform3d().compose(R, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = Transform3d().scale(2, 1, 3).translate(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.ops import knn_points\n",
    "\n",
    "N, P1, P2, D, K = 32, 128, 256, 3, 1\n",
    "\n",
    "pts1 = torch.randn(N, P1, D)\n",
    "pts2 = torch.rand(N, P2, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1.4290e+00],\n",
       "          [8.4930e-03],\n",
       "          [2.2461e-01],\n",
       "          ...,\n",
       "          [1.4522e-01],\n",
       "          [4.4890e+00],\n",
       "          [1.4988e+00]],\n",
       " \n",
       "         [[3.0449e-01],\n",
       "          [9.2938e-01],\n",
       "          [1.0291e+01],\n",
       "          ...,\n",
       "          [6.4463e-02],\n",
       "          [1.7473e+00],\n",
       "          [2.9075e+00]],\n",
       " \n",
       "         [[9.9870e-01],\n",
       "          [1.5493e+00],\n",
       "          [4.5603e-01],\n",
       "          ...,\n",
       "          [1.3994e-01],\n",
       "          [8.1903e+00],\n",
       "          [6.6683e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.8013e+00],\n",
       "          [7.1657e-01],\n",
       "          [2.8127e+00],\n",
       "          ...,\n",
       "          [4.2455e+00],\n",
       "          [2.5243e-01],\n",
       "          [4.6955e+00]],\n",
       " \n",
       "         [[2.8929e-01],\n",
       "          [1.8864e+00],\n",
       "          [9.6867e-01],\n",
       "          ...,\n",
       "          [4.2351e-01],\n",
       "          [7.0330e-01],\n",
       "          [9.7388e-01]],\n",
       " \n",
       "         [[4.6270e+00],\n",
       "          [7.8505e-01],\n",
       "          [2.8509e-01],\n",
       "          ...,\n",
       "          [2.3710e+00],\n",
       "          [7.8456e-02],\n",
       "          [8.3677e+00]]]),\n",
       " tensor([[[181],\n",
       "          [ 58],\n",
       "          [226],\n",
       "          ...,\n",
       "          [ 47],\n",
       "          [233],\n",
       "          [ 12]],\n",
       " \n",
       "         [[ 75],\n",
       "          [ 49],\n",
       "          [245],\n",
       "          ...,\n",
       "          [196],\n",
       "          [  0],\n",
       "          [202]],\n",
       " \n",
       "         [[151],\n",
       "          [193],\n",
       "          [ 23],\n",
       "          ...,\n",
       "          [200],\n",
       "          [104],\n",
       "          [104]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[172],\n",
       "          [137],\n",
       "          [123],\n",
       "          ...,\n",
       "          [155],\n",
       "          [209],\n",
       "          [196]],\n",
       " \n",
       "         [[ 74],\n",
       "          [216],\n",
       "          [ 54],\n",
       "          ...,\n",
       "          [216],\n",
       "          [ 98],\n",
       "          [ 18]],\n",
       " \n",
       "         [[ 53],\n",
       "          [198],\n",
       "          [145],\n",
       "          ...,\n",
       "          [243],\n",
       "          [ 84],\n",
       "          [ 84]]]),\n",
       " None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists, idx, knn = knn_points(pts1, pts2, K=K)\n",
    "dists, idx, knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'input_dim' and 'output_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-877d4d94ba32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphConv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'input_dim' and 'output_dim'"
     ]
    }
   ],
   "source": [
    "from pytorch3d.ops import GraphConv\n",
    "\n",
    "conv = GraphConv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.utils import ico_sphere\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.loss import chamfer_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0052)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sphere_mesh1 = ico_sphere(level=3)\n",
    "sphere_mesh2 = ico_sphere(level=1)\n",
    "\n",
    "sample_sphere = sample_points_from_meshes(sphere_mesh1, 5000)\n",
    "sample_test = sample_points_from_meshes(sphere_mesh2, 5000)\n",
    "\n",
    "loss_chamfer, _ = chamfer_distance(sample_sphere, sample_test)\n",
    "loss_chamfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.renderer import (\n",
    "    OpenGLPerspectiveCameras, look_at_view_transform,\n",
    "    RasterizationSettings, BlendParams,\n",
    "    MeshRenderer, MeshRasterizer, HardPhongShader,\n",
    ")\n",
    "\n",
    "R, T = look_at_view_transform(2.7, 10, 20)\n",
    "cameras = OpenGLPerspectiveCameras(device=torch.device(\"cuda\"), R=R, T=T)\n",
    "\n",
    "raster_settings = RasterizationSettings(\n",
    "    image_size=512,\n",
    "    blur_radius=0.0,\n",
    "    faces_per_pixel=1, # Sets the value of K\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-68953d247109>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     rasterizer=MeshRasterizer(cameras=cameras, \n\u001b[1;32m      4\u001b[0m         raster_settings=raster_settings),\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mshader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHardPhongShader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcameras\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcameras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "evice=torch.device(\"cuda\")\n",
    "renderer = MeshRenderer(\n",
    "    rasterizer=MeshRasterizer(cameras=cameras, \n",
    "        raster_settings=raster_settings),\n",
    "    shader=HardPhongShader(device=device, cameras=cameras)\n",
    ")\n",
    "\n",
    "image = renderer(mesh)\n",
    "\n",
    "# compute  a loss give a ground truth image\n",
    "loss = (gt_img - img).sum()\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_0.3",
   "language": "python",
   "name": "pytorch3d_0.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
