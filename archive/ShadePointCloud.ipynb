{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Materials()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    FoVPerspectiveCameras, \n",
    "    PointLights, \n",
    "    DirectionalLights, \n",
    "    Materials, \n",
    "    RasterizationSettings, \n",
    "    MeshRenderer, \n",
    "    MeshRasterizer,  \n",
    "    SoftPhongShader,\n",
    "    TexturesUV\n",
    ")\n",
    "m = Materials()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.]]), tensor([[1., 1., 1.]]), tensor([[1., 1., 1.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.ambient_color, m.diffuse_color, m.specular_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeshRenderer(nn.Module):\n",
    "    \"\"\"\n",
    "    A class for rendering a batch of heterogeneous meshes. The class should\n",
    "    be initialized with a rasterizer and shader class which each have a forward\n",
    "    function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rasterizer, shader):\n",
    "        super().__init__()\n",
    "        self.rasterizer = rasterizer\n",
    "        self.shader = shader\n",
    "\n",
    "    def to(self, device):        \n",
    "        self.rasterizer.to(device)\n",
    "        self.shader.to(device)\n",
    "        return self\n",
    "\n",
    "    def forward(self, meshes_world, **kwargs) -> torch.Tensor:        \n",
    "        fragments = self.rasterizer(meshes_world, **kwargs)\n",
    "        images = self.shader(fragments, meshes_world, **kwargs)\n",
    "\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftPhongShader(nn.Module):\n",
    "    \"\"\"\n",
    "    Per pixel lighting - the lighting model is applied using the interpolated\n",
    "    coordinates and normals for each pixel. The blending function returns the\n",
    "    soft aggregated color using all the faces per pixel.\n",
    "    To use the default values, simply initialize the shader with the desired\n",
    "    device e.g.\n",
    "    .. code-block::\n",
    "        shader = SoftPhongShader(device=torch.device(\"cuda:0\"))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, device=\"cpu\", cameras=None, lights=None, materials=None, blend_params=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lights = lights if lights is not None else PointLights(device=device)\n",
    "        self.materials = (\n",
    "            materials if materials is not None else Materials(device=device)\n",
    "        )\n",
    "        self.cameras = cameras\n",
    "        self.blend_params = blend_params if blend_params is not None else BlendParams()\n",
    "\n",
    "    def to(self, device):\n",
    "        # Manually move to device modules which are not subclasses of nn.Module\n",
    "        self.cameras = self.cameras.to(device)\n",
    "        self.materials = self.materials.to(device)\n",
    "        self.lights = self.lights.to(device)\n",
    "        return self\n",
    "\n",
    "    def forward(self, fragments, meshes, **kwargs) -> torch.Tensor:\n",
    "        cameras = kwargs.get(\"cameras\", self.cameras)\n",
    "        if cameras is None:\n",
    "            msg = \"Cameras must be specified either at initialization \\\n",
    "                or in the forward pass of SoftPhongShader\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        texels = meshes.sample_textures(fragments)\n",
    "        lights = kwargs.get(\"lights\", self.lights)\n",
    "        materials = kwargs.get(\"materials\", self.materials)\n",
    "        blend_params = kwargs.get(\"blend_params\", self.blend_params)\n",
    "        colors = phong_shading(\n",
    "            meshes=meshes,\n",
    "            fragments=fragments,\n",
    "            texels=texels,\n",
    "            lights=lights,\n",
    "            cameras=cameras,\n",
    "            materials=materials,\n",
    "        )\n",
    "        znear = kwargs.get(\"znear\", getattr(cameras, \"znear\", 1.0))\n",
    "        zfar = kwargs.get(\"zfar\", getattr(cameras, \"zfar\", 100.0))\n",
    "        images = softmax_rgb_blend(\n",
    "            colors, fragments, blend_params, znear=znear, zfar=zfar\n",
    "        )\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phong_shading(\n",
    "    meshes, fragments, lights, cameras, materials, texels\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Apply per pixel shading. First interpolate the vertex normals and\n",
    "    vertex coordinates using the barycentric coordinates to get the position\n",
    "    and normal at each pixel. Then compute the illumination for each pixel.\n",
    "    The pixel color is obtained by multiplying the pixel textures by the ambient\n",
    "    and diffuse illumination and adding the specular component.\n",
    "    Args:\n",
    "        meshes: Batch of meshes\n",
    "        fragments: Fragments named tuple with the outputs of rasterization\n",
    "        lights: Lights class containing a batch of lights\n",
    "        cameras: Cameras class containing a batch of cameras\n",
    "        materials: Materials class containing a batch of material properties\n",
    "        texels: texture per pixel of shape (N, H, W, K, 3)\n",
    "    Returns:\n",
    "        colors: (N, H, W, K, 3)\n",
    "    \"\"\"\n",
    "    verts = meshes.verts_packed()  # (V, 3)\n",
    "    faces = meshes.faces_packed()  # (F, 3)\n",
    "    vertex_normals = meshes.verts_normals_packed()  # (V, 3)\n",
    "    faces_verts = verts[faces]\n",
    "    faces_normals = vertex_normals[faces]\n",
    "    pixel_coords = interpolate_face_attributes(\n",
    "        fragments.pix_to_face, fragments.bary_coords, faces_verts\n",
    "    )\n",
    "    pixel_normals = interpolate_face_attributes(\n",
    "        fragments.pix_to_face, fragments.bary_coords, faces_normals\n",
    "    )\n",
    "    ambient, diffuse, specular = _apply_lighting(\n",
    "        pixel_coords, pixel_normals, lights, cameras, materials\n",
    "    )\n",
    "    colors = (ambient + diffuse) * texels + specular\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_lighting(\n",
    "    points, normals, lights, cameras, materials\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        points: torch tensor of shape (N, P, 3) or (P, 3).\n",
    "        normals: torch tensor of shape (N, P, 3) or (P, 3)\n",
    "        lights: instance of the Lights class.\n",
    "        cameras: instance of the Cameras class.\n",
    "        materials: instance of the Materials class.\n",
    "    Returns:\n",
    "        ambient_color: same shape as materials.ambient_color\n",
    "        diffuse_color: same shape as the input points\n",
    "        specular_color: same shape as the input points\n",
    "    \"\"\"\n",
    "    light_diffuse = lights.diffuse(normals=normals, points=points)\n",
    "    light_specular = lights.specular(\n",
    "        normals=normals,\n",
    "        points=points,\n",
    "        camera_position=cameras.get_camera_center(),\n",
    "        shininess=materials.shininess,\n",
    "    )\n",
    "    ambient_color = materials.ambient_color * lights.ambient_color\n",
    "    diffuse_color = materials.diffuse_color * light_diffuse\n",
    "    specular_color = materials.specular_color * light_specular\n",
    "    if normals.dim() == 2 and points.dim() == 2:\n",
    "        # If given packed inputs remove batch dim in output.\n",
    "        return (\n",
    "            ambient_color.squeeze(),\n",
    "            diffuse_color.squeeze(),\n",
    "            specular_color.squeeze(),\n",
    "        )\n",
    "    return ambient_color, diffuse_color, specular_color"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_0.3",
   "language": "python",
   "name": "pytorch3d_0.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
