{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 512, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Trainer at 0x7fb129859580>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import math \n",
    "import os\n",
    "import trimesh\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from src.data.adversarial import AdversarialDataProvider\n",
    "from src.data.reconstruction import ReconstructionDataProvider\n",
    "from src.models.stylist import Stylist\n",
    "from src.models.generator import Generator\n",
    "from src.models.discriminator import Discriminator\n",
    "from src.render.mesh_renderer import MeshPointsRenderer\n",
    "from src.utilities.util import make_faces, grid_to_list\n",
    "\n",
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.G_noise_amp =  config.G_noise_amp\n",
    "        self.z_size = config.latent_size\n",
    "        size = config.adversarial_data_patch_size\n",
    "        self.faces = make_faces(size, size)\n",
    "        \n",
    "        self.device = torch.device(\"cuda\")\n",
    "        \n",
    "        self.writer = SummaryWriter()\n",
    "        # Data providers\n",
    "        self.RDP = ReconstructionDataProvider(config)\n",
    "        self.ADP = AdversarialDataProvider(config)\n",
    "        \n",
    "        self.S = Stylist(config).to(self.device)\n",
    "        self.G = Generator(config).to(self.device)\n",
    "        self.D = Discriminator(config).to(self.device)\n",
    "        self.R = MeshPointsRenderer(config).to(self.device)\n",
    "        self.R.setup(self.device)\n",
    "        \n",
    "        # Optimizers\n",
    "        self.optim_G = torch.optim.Adam(self.G.parameters(), lr=0.0001)\n",
    "        self.optim_S = torch.optim.Adam(self.S.parameters(), lr=0.0001)\n",
    "        self.optim_D = torch.optim.Adam(self.D.parameters(), lr=0.0001)\n",
    "        # Loss functions\n",
    "        self.adversarial_loss = nn.BCELoss()\n",
    "        #self.reconstruction_loss = nn.L1Loss()\n",
    "        self.reconstruction_loss = nn.MSELoss()\n",
    "        \n",
    "    def step(self):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def adversarial_step(self):\n",
    "        batch, mean_std = self.ADP.next_batch(labels=True, device=self.device)\n",
    "        images, points = batch['large'], batch['points'] # ?????\n",
    "        label_real = batch['label_real']\n",
    "        label_fake = batch['label_fake']\n",
    "        \n",
    "        # (1) Update Discriminator\n",
    "        ## Train with all-real batch\n",
    "        self.optim_D.zero_grad()\n",
    "        output = self.D(images)        \n",
    "        errD_real =  self.adversarial_loss(output, label_real)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item() \n",
    "        \n",
    "        ## Train with all-fake batch\n",
    "        style = self.S(images)\n",
    "        pts =  self.G(points, style)\n",
    "        g_images = self.R(pts, mean_std=mean_std, align=True)\n",
    "        output = self.D(g_images.detach())  \n",
    "        errD_fake = self.adversarial_loss(output, label_fake)    \n",
    "        errD_fake.backward()\n",
    "        \n",
    "        self.optim_D.step()\n",
    "        \n",
    "        # (2) Update Generator and Stylist\n",
    "        self.optim_S.zero_grad()\n",
    "        self.optim_G.zero_grad()\n",
    "        \n",
    "        output = self.D(g_images)    \n",
    "        errG = self.adversarial_loss(output, label_real)\n",
    "        errG.backward()\n",
    "        \n",
    "        self.optim_S.step()\n",
    "        self.optim_G.step()                \n",
    "        \n",
    "        return {\n",
    "            'errD_real': errD_real.item(),\n",
    "            'errD_fake': errD_fake.item(),\n",
    "            'errD': (errD_real + errD_fake).item(),\n",
    "            'errG': errD_fake.item(),\n",
    "        }\n",
    "        \n",
    "    def reconstruction_step(self):\n",
    "        batch = self.RDP.next_batch(self.device)        \n",
    "        pts_fine = batch['points']\n",
    "        bs = pts_fine.size(0)\n",
    "        \n",
    "        pts_noise = pts_fine + torch.randn_like(pts_fine) * self.G_noise_amp\n",
    "        style = torch.zeros(bs, self.z_size, device=self.device)\n",
    "        \n",
    "        self.optim_G.zero_grad()\n",
    "        \n",
    "        vertices = self.G(pts_noise, style)\n",
    "        errG_rec = self.reconstruction_loss(vertices, pts_fine) * 10\n",
    "        \n",
    "        errG_rec.backward()\n",
    "        \n",
    "        self.optim_G.step()\n",
    "        return {\n",
    "            'errG_rec': errG_rec.item(),\n",
    "        }\n",
    "    \n",
    "    def checkpoint(self, log_dir, step):\n",
    "        torch.save(self.G.state_dict(), os.path.join(log_dir, f'G{step}.pth'))\n",
    "        torch.save(self.S.state_dict(), os.path.join(log_dir, f'S{step}.pth'))\n",
    "        torch.save(self.D.state_dict(), os.path.join(log_dir, f'D{step}.pth'))\n",
    "    \n",
    "    def log_loss(self, losses, step_no):\n",
    "        for key in losses.keys():\n",
    "            self.writer.add_scalar(f'Loss/{key}', losses[key], step_no)\n",
    "    \n",
    "    def log_stl(self, step_no):\n",
    "        mesh_dir = os.path.join(self.writer.log_dir, 'mesh')\n",
    "        if not os.path.exists(mesh_dir):\n",
    "            os.makedirs(mesh_dir)\n",
    "            \n",
    "        batch, mean_std = self.ADP.next_batch(labels=False, device=self.device)\n",
    "        images, points = batch['large'], batch['points']                \n",
    "                \n",
    "        with torch.no_grad():\n",
    "            style = self.S(images)\n",
    "            style[0] = 0 # Default style\n",
    "            pts_batch =  grid_to_list(self.G(points, style))\n",
    "            for i, pts in enumerate(pts_batch):\n",
    "                vertices = pts.detach().cpu()\n",
    "                mesh = trimesh.Trimesh(vertices=vertices, faces=self.faces)\n",
    "                mesh.export(os.path.join(mesh_dir, f'mesh_{step_no}_{i}.stl'))\n",
    "                \n",
    "    def log_images(self, step_no):\n",
    "        batch, _ = self.ADP.next_batch(labels=False, device=self.device)\n",
    "        images, points = batch['large'], batch['points'] \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            style = self.S(images)\n",
    "            style[0] = 0 # Default style\n",
    "            pts =  self.G(points, style)\n",
    "            pts[-1] = points[-1] # One default point\n",
    "            \n",
    "            g_images = self.R(pts, mean_std=None, align=False)\n",
    "            print(g_images.shape)\n",
    "            nrow = math.ceil(g_images.size(0) / 2.)\n",
    "            grid = torchvision.utils.make_grid(g_images, nrow=nrow)\n",
    "            self.writer.add_image('images', grid, step_no)\n",
    "            \n",
    "        \n",
    "\n",
    "from src.config import get_parser\n",
    "\n",
    "config = get_parser().parse_args(args=[])    \n",
    "\n",
    "trainer = Trainer(config)\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "steps = len(trainer.RDP) + len(trainer.ADP)\n",
    "\n",
    "threshold = len(trainer.RDP) / len(trainer.ADP)\n",
    "\n",
    "for epoch_no in range(1, epochs):\n",
    "    for step_no in range(steps):\n",
    "        if  random.random() < 0.5: #threshold:\n",
    "            losses = trainer.reconstruction_step()\n",
    "        else:\n",
    "            losses = trainer.adversarial_step()\n",
    "        trainer.log_loss(losses, epoch_no * steps + step_no)\n",
    "        if step_no > 0 and step_no % 100 == 0:\n",
    "            trainer.log_stl(step_no)\n",
    "    print(epoch_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "self = trainer\n",
    "\n",
    "batch, _ = self.ADP.next_batch(labels=False, device=self.device)\n",
    "images, points = batch['large'], batch['points'] \n",
    "\n",
    "g_images_2 = self.R(points, mean_std=None, align=False)\n",
    "print(g_images_2.shape)\n",
    "grid_2 = torchvision.utils.make_grid(g_images_2, nrow=4)\n",
    "#self.writer.add_image('images', grid, step_no+1)\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(grid_2.permute(1, 2, 0).cpu()); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_0.3",
   "language": "python",
   "name": "pytorch3d_0.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
