{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.FullDataset at 0x7fe8e82260d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Grayscale,\n",
    "    Normalize,\n",
    "    Resize,\n",
    "    RandomHorizontalFlip,\n",
    "    ToTensor,\n",
    "    ToPILImage,\n",
    ")\n",
    "from pytorch3d.io import load_obj, save_obj\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.structures import Meshes\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from src.utilities.util import scale_geometry\n",
    "from src.augment.geoaug import GeoAugment\n",
    "\n",
    "def pyramid_transform(img_size, mask_size,  mean=0, std=1):\n",
    "    transform = {\n",
    "        'preprocess': Compose([\n",
    "            Resize([mask_size, mask_size]),\n",
    "            ToTensor(),            \n",
    "        ]),\n",
    "        'head': Compose([\n",
    "            ToPILImage(),\n",
    "            RandomHorizontalFlip(),            \n",
    "        ]),\n",
    "        'image': Compose([\n",
    "            Resize([img_size, img_size]),\n",
    "            Grayscale(),\n",
    "            ToTensor(),\n",
    "            Normalize(mean=(mean), std=(std)),\n",
    "\n",
    "        ]),        \n",
    "    }\n",
    "    def final_transform(img, mask):\n",
    "        img = transform['preprocess'](img)\n",
    "        img = img * mask        \n",
    "        flipped = transform['head'](img)\n",
    "        return {\n",
    "            'image': transform['image'](flipped),            \n",
    "        }\n",
    "    return final_transform\n",
    "\n",
    "class FullDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \n",
    "        self.num_workers = config.num_workers\n",
    "        self.pin_memory = config.pin_memory        \n",
    "        self.outline_size =  config.fast_outline_size\n",
    "        self.baseline_size = config.fast_baseline_size\n",
    "        self.stl_offset =  config.stl_offset\n",
    "        self.geoaug_policy = config.geoaug_policy\n",
    "\n",
    "        self.image_root = config.fast_image_root\n",
    "        self.mask_root = config.mask_root            \n",
    "        self.image_size = config.fast_image_size\n",
    "        self.mask_size = config.mask_size\n",
    "        self.image_mean = config.fast_image_mean\n",
    "        self.image_std = config.fast_image_std\n",
    "        \n",
    "        self.data_grid_dir = config.data_grid_dir\n",
    "        self.data_mesh_dir = config.data_mesh_dir\n",
    "        \n",
    "        \n",
    "        blueprint = np.load(os.path.join(config.data_dir, config.blueprint))\n",
    "        points = torch.tensor(blueprint['points'])                \n",
    "                       \n",
    "        self.points = self.scale(points, self.outline_size)                \n",
    "        \n",
    "        self.transform = pyramid_transform(self.image_size, self.mask_size, \n",
    "                                           self.image_mean, self.image_std)\n",
    "        self.img_ds = ImageFolder(self.image_root)\n",
    "        \n",
    "        self.grid_files = [os.path.join(self.data_grid_dir, f) \n",
    "                           for f in os.listdir(self.data_grid_dir)]\n",
    "        self.mesh_files = [os.path.join(self.data_mesh_dir, f) \n",
    "                           for f in os.listdir(self.data_mesh_dir)]\n",
    "        self.device = torch.device('cpu')\n",
    "        \n",
    "    def scale(self, t, size):\n",
    "        return F.interpolate(t, size=size, mode='bilinear', align_corners=True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_ds)\n",
    "    \n",
    "    def get_samples(self, idx):\n",
    "        idx_mesh = idx % len(self.mesh_files)\n",
    "        mesh_file= self.mesh_files[idx_mesh]\n",
    "        verts, faces = scale_geometry(mesh_file, self.device, offset=self.stl_offset)\n",
    "        trg_mesh = Meshes(verts=[verts], faces=[faces])\n",
    "        samples = sample_points_from_meshes(trg_mesh, self.baseline_size ** 2)[0]\n",
    "        samples = samples.t().reshape(3, self.baseline_size, self.baseline_size)\n",
    "        return samples.contiguous()\n",
    "    \n",
    "    def get_grid(self, idx):\n",
    "        idx_grid = idx % len(self.grid_files)\n",
    "        grid_file =  self.grid_files[idx_grid]\n",
    "        grid = torch.load(grid_file)\n",
    "        vertices, normals = grid['vertices'][None], grid['normals'][None]\n",
    "        vertices = self.scale(vertices, self.baseline_size)\n",
    "        normals = self.scale(normals, self.baseline_size)\n",
    "        normals = F.normalize(normals, dim=1)\n",
    "        return vertices[0], normals[0]\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):              \n",
    "        # Image\n",
    "        idx_img = idx % len(self.img_ds)\n",
    "        image, _ = self.img_ds[idx_img]\n",
    "        mask_path =  self.img_ds.imgs[0][0].replace(self.image_root, self.mask_root)\n",
    "        mask = torch.load(mask_path.replace('.png', '.pth'))\n",
    "        res = self.transform(image, mask)        \n",
    "        \n",
    "        # Mesh        \n",
    "        res['samples'] = self.get_samples(idx)\n",
    "        \n",
    "        vertices, normals = self.get_grid(idx)\n",
    "        res['vertices'] = vertices\n",
    "        res['normals'] = normals        \n",
    "        #points = self.points[idx % self.points.size(0)]        \n",
    "        #res['outline'] = GeoAugment(points, policy=self.geoaug_policy)                 \n",
    "        return res\n",
    "    \n",
    "from src.config import get_parser\n",
    "\n",
    "config = get_parser().parse_args(args=[])\n",
    "ds = FullDataset(config)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image torch.Size([1, 128, 128])\n",
      "samples torch.Size([3, 128, 128])\n",
      "vertices torch.Size([3, 128, 128])\n",
      "normals torch.Size([3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "res = ds[0]\n",
    "for key in res.keys():\n",
    "    print(key, res[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image torch.Size([1, 128, 128])\n",
      "samples torch.Size([3, 128, 128])\n",
      "vertices torch.Size([3, 128, 128])\n",
      "normals torch.Size([3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "from src.data.full_dataset import FullDataset\n",
    "\n",
    "from src.config import get_parser\n",
    "\n",
    "config = get_parser().parse_args(args=[])\n",
    "ds = FullDataset(config)\n",
    "res = ds[110]\n",
    "for key in res.keys():\n",
    "    print(key, res[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_0.3",
   "language": "python",
   "name": "pytorch3d_0.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
