{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train generator and discriminator \n",
    "# directly on surface\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch3d.loss import (\n",
    "    chamfer_distance,    \n",
    ")\n",
    "\n",
    "from src.callback.log_mesh import LogMesh\n",
    "from src.utilities.util import grid_to_list\n",
    "from src.models.discriminator import Discriminator\n",
    "from src.models.surface_generator import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DirectGAN(\n",
       "  (G): Generator(\n",
       "    (points): SurfaceGenerator(\n",
       "      (trunk): Sequential(\n",
       "        (head): ConvBlock(\n",
       "          (conv): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "        (main): Sequential(\n",
       "          (b0): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "          )\n",
       "          (b1): UpConvBlock(\n",
       "            (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "          )\n",
       "          (b2): UpConvBlock(\n",
       "            (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (points): Sequential(\n",
       "        (0): Conv2d(256, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (D): Discriminator(\n",
       "    (encoder): Encoder(\n",
       "      (b0): DownBlock(\n",
       "        (conv): ConvBlock(\n",
       "          (conv): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "        (main): Sequential(\n",
       "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (conv): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (b1): DownBlock(\n",
       "        (conv): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "        (main): Sequential(\n",
       "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (conv): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (b2): DownBlock(\n",
       "        (conv): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "        (main): Sequential(\n",
       "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (conv): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): Classifier(\n",
       "      (conv): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (b0): UpBlock(\n",
       "        (conv): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "        (main): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "      )\n",
       "      (b1): UpBlock(\n",
       "        (conv): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "        (main): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "      )\n",
       "      (b2): UpBlock(\n",
       "        (conv): ConvBlock(\n",
       "          (conv): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "        (main): ConvBlock(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DirectGAN(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()        \n",
    "        self.save_hyperparameters(hparams)\n",
    "        \n",
    "        self.G = Generator(hparams)\n",
    "        self.D = Discriminator(hparams)\n",
    "        \n",
    "        \n",
    "    def forward(self, outline):\n",
    "        return self.G(outline)\n",
    "    \n",
    "    def log_all(self, r, p, d):\n",
    "        for k, v in  d.items(): \n",
    "            self.log(f\"{r}_loss_{p}/{k}\", v)        \n",
    "            \n",
    "    def adversarial_loss(self, lbl, is_real):\n",
    "        trg = torch.ones_like(lbl) if is_real else torch.zeros_like(lbl)\n",
    "        return F.binary_cross_entropy(lbl, trg)\n",
    "    \n",
    "    def train_generator(self, vertices, batch):\n",
    "        rcn = F.l1_loss(vertices, batch['baseline'])        \n",
    "        lbl, _ = self.D(vertices, False)        \n",
    "        adv = self.adversarial_loss(lbl, False)        \n",
    "        loss = rcn + adv\n",
    "        log =  {\n",
    "            'G_loss' : loss.item(),\n",
    "            'G_rcn': rcn.item(),            \n",
    "            'G_adv': adv.item(),            \n",
    "        }        \n",
    "        return loss, log\n",
    "    \n",
    "    def train_discriminator(self, vertices, batch):\n",
    "        # Real\n",
    "        lbl_r, decodings = self.D(batch['baseline'], True)        \n",
    "        adv_r = self.adversarial_loss(lbl_r, True)                        \n",
    "        dcd = F.l1_loss(decodings, vertices)                \n",
    "        # Fake                \n",
    "        lbl_f, _ = self.D(vertices, False)                \n",
    "        adv_f = self.adversarial_loss(lbl_f, False)\n",
    "        \n",
    "        loss = adv_r + dcd + adv_f\n",
    "        log = {\n",
    "            'D_loss' : loss.item(),\n",
    "            'D_adv_r' : adv_r.item(),            \n",
    "            'D_dcd' : dcd.item(),\n",
    "            'D_adv_f' : adv_f.item(),\n",
    "        }        \n",
    "        return loss, log\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        vertices = self.G(batch['outline'])\n",
    "        loss = 0\n",
    "        if optimizer_idx == 0:            \n",
    "            loss, log = self.train_discriminator(vertices, batch)        \n",
    "            self.log_all('train', 'D', log)\n",
    "        elif optimizer_idx == 1:            \n",
    "            loss, log = self.train_generator(vertices, batch)\n",
    "            self.log_all('train', 'G', log)            \n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        vertices = self.G(batch['outline'])\n",
    "        _, log = self.train_discriminator(vertices, batch)        \n",
    "        self.log_all('val', 'D', log)   \n",
    "        _, log = self.train_generator(vertices, batch)\n",
    "        self.log_all('val', 'G', log)     \n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        lr, betas = 0.0003, (0.5, 0.999)\n",
    "        opt_d = torch.optim.Adam(self.D.parameters(), lr=lr, betas=betas)\n",
    "        opt_g = torch.optim.Adam(self.G.parameters(),  lr=lr, betas=betas)\n",
    "        return [opt_d, opt_g], []\n",
    "    \n",
    "    \n",
    "\n",
    "from src.config import get_parser\n",
    "\n",
    "config = get_parser().parse_args(args=[])   \n",
    "\n",
    "config.log_mesh_interval = 100\n",
    "#config.fast_outline_size =  32\n",
    "#config.fast_baseline_size = 128\n",
    "#config.fast_image_size = 128\n",
    "config.fast_batch_size = 32\n",
    "config.raster_faces_per_pixel = 4\n",
    "config.G_noise_amp = 0.005 #0.002\n",
    "config.geoaug_policy = 'scaling'\n",
    "#config.fast_discriminator_channels[0] = 3\n",
    "\n",
    "\n",
    "model = DirectGAN(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.data.surface_datamodule.SurfaceDataModule at 0x7f7292803430>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data.surface_datamodule import SurfaceDataModule\n",
    "\n",
    "dm = SurfaceDataModule(config)    \n",
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type          | Params\n",
      "---------------------------------------\n",
      "0 | G    | Generator     | 1.0 M \n",
      "1 | D    | Discriminator | 1.5 M \n",
      "---------------------------------------\n",
      "2.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 M     Total params\n",
      "10.097    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c464ed08b2b240afa673a6f07f0b5dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148d44bec32749ec98f6f2330547706d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, max_epochs=100, progress_bar_refresh_rate=20,\n",
    "                     terminate_on_nan=True, \n",
    "                     #profiler=\"pytorch\",\n",
    "                     log_every_n_steps=2, \n",
    "                     callbacks=[LogMesh(config)]\n",
    "                    )\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_05",
   "language": "python",
   "name": "pytorch3d_05"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
