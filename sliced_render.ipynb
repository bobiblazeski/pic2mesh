{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image torch.Size([1, 128, 128])\n",
      "slice_data torch.Size([3, 16, 16])\n",
      "slice_idx torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Grayscale,\n",
    "    Normalize,\n",
    "    Resize,\n",
    "    RandomHorizontalFlip,\n",
    "    ToTensor,    \n",
    ")\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src.utilities.util import (\n",
    "    grid_to_list,\n",
    "    list_to_grid,\n",
    ")\n",
    "def pyramid_transform(img_size, mean=0, std=1):\n",
    "    transform = Compose([            \n",
    "        Resize([img_size, img_size]),\n",
    "        RandomHorizontalFlip(),\n",
    "        Grayscale(),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=(mean), std=(std)),\n",
    "    ])\n",
    "    def final_transform(img):        \n",
    "        return transform(img)\n",
    "    \n",
    "    return final_transform\n",
    "\n",
    "class SlicedRenderDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, config):        \n",
    "        self.image_root = config.data_renders_dir        \n",
    "        self.image_mean = config.fast_image_mean\n",
    "        self.image_std = config.fast_image_std\n",
    "        self.image_size = config.fast_image_size\n",
    "        self.full_size = config.grid_full_size\n",
    "        self.slice_size = config.grid_slice_size\n",
    "                \n",
    "        self.transform = pyramid_transform(self.image_size, \n",
    "                                           self.image_mean, self.image_std)\n",
    "        self.img_ds = ImageFolder(self.image_root, transform=self.transform)\n",
    "        self.slice_indices = self.make_indices(self.full_size - self.slice_size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_ds) * len(self.slice_indices)\n",
    "    \n",
    "    def make_indices(self, n):         \n",
    "        t = torch.arange(n)\n",
    "        return torch.stack(torch.torch.meshgrid(t, t), dim=-1).reshape(-1, 2)\n",
    "    \n",
    "    def scale(self, t, size):\n",
    "        return F.interpolate(t, size=size, mode='bilinear', align_corners=True)    \n",
    "    \n",
    "    def get_grid(self, idx):\n",
    "        f =  self.img_ds.imgs[idx][0]\n",
    "        f = f.replace('renders', 'grid').replace('.png', '.pth')\n",
    "        grid = list_to_grid(torch.load(f)[None])        \n",
    "        grid = self.scale(grid, self.full_size)[0]\n",
    "        return grid\n",
    "    \n",
    "    def get_slice(self, idx):\n",
    "        grid = self.get_grid(idx % len(self.img_ds))\n",
    "        indices = self.slice_indices[idx % len(self.slice_indices)]\n",
    "        r, c = indices\n",
    "        return (grid[:, r:r+self.slice_size, c:c+self.slice_size],\n",
    "                indices)\n",
    "   \n",
    "    def __getitem__(self, idx):              \n",
    "        res = {}        \n",
    "        image, label = self.img_ds[idx % len(self.img_ds)]\n",
    "        res['image'] =  image\n",
    "        #res['label'] =  label\n",
    "        slice_data, slice_idx = self.get_slice(idx)\n",
    "        res['slice_data'] = slice_data\n",
    "        res['slice_idx'] = slice_idx\n",
    "        return res\n",
    "\n",
    "class SlicedRenderDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.batch_size = config.fast_batch_size\n",
    "        self.num_workers = config.num_workers\n",
    "        self.pin_memory = config.pin_memory\n",
    "        self.train_ds = SlicedRenderDataset(self.config)         \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, shuffle=True, batch_size=self.batch_size, \n",
    "            num_workers=self.num_workers, pin_memory=self.pin_memory)        \n",
    "    \n",
    "from src.config import get_parser\n",
    "\n",
    "config = get_parser().parse_args(args=[]) \n",
    "ds = SampleRenderDataset(config)\n",
    "ds0 = ds[0]\n",
    "for k,v in ds0.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SlicedRenderDataModule at 0x7ff86735acd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = SlicedRenderDataModule(config)\n",
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595200"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dm.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 32, 4761600)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.slice_size, ds.full_size, len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10\n",
      "0 11\n",
      "0 12\n",
      "1 10\n",
      "1 11\n",
      "1 12\n",
      "2 10\n",
      "2 11\n",
      "2 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_full_size = 5\n",
    "grid_slice_size = 2\n",
    "res =  []\n",
    "for r in range(grid_full_size-grid_slice_size):\n",
    "    for c in range(grid_full_size-grid_slice_size):\n",
    "        res.append((r, c+10)) \n",
    "        print(r, c+10)\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0, 10],\n",
       "         [ 0, 11],\n",
       "         [ 0, 12],\n",
       "         [ 1, 10],\n",
       "         [ 1, 11],\n",
       "         [ 1, 12],\n",
       "         [ 2, 10],\n",
       "         [ 2, 11],\n",
       "         [ 2, 12]]),\n",
       " torch.Size([9, 2]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = grid_full_size-grid_slice_size\n",
    "t = torch.arange(n)\n",
    "r = torch.stack(torch.torch.meshgrid(t, t+10), dim=-1).reshape(-1, 2)\n",
    "r, r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_0.3",
   "language": "python",
   "name": "pytorch3d_0.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
