{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EqualizedModConv2d(3, 12, 3, upsample=False, downsample=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "-------------------------------------------------\n",
    "   File Name:    CustomLayers.py\n",
    "   Author:       Zhonghao Huang\n",
    "   Date:         2019/12/13\n",
    "   Description:  Modified from:\n",
    "                 https://github.com/akanimax/pro_gan_pytorch\n",
    "                 https://github.com/lernapparat/lernapparat\n",
    "                 https://github.com/NVlabs/stylegan\n",
    "-------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.stylegan2.op import fused_leaky_relu, upfirdn2d\n",
    "\n",
    "\n",
    "def make_kernel(k):\n",
    "    k = torch.tensor(k, dtype=torch.float32)\n",
    "\n",
    "    if k.ndim == 1:\n",
    "        k = k[None, :] * k[:, None]\n",
    "\n",
    "    k /= k.sum()\n",
    "\n",
    "    return k\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, kernel, factor=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.factor = factor\n",
    "        kernel = make_kernel(kernel) * (factor ** 2)\n",
    "        self.register_buffer('kernel', kernel)\n",
    "\n",
    "        p = kernel.shape[0] - factor\n",
    "\n",
    "        pad0 = (p + 1) // 2 + factor - 1\n",
    "        pad1 = p // 2\n",
    "\n",
    "        self.pad = (pad0, pad1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = upfirdn2d(input, self.kernel, up=self.factor,\n",
    "                        down=1, pad=self.pad)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, kernel, factor=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.factor = factor\n",
    "        kernel = make_kernel(kernel)\n",
    "        self.register_buffer('kernel', kernel)\n",
    "\n",
    "        p = kernel.shape[0] - factor\n",
    "\n",
    "        pad0 = (p + 1) // 2\n",
    "        pad1 = p // 2\n",
    "\n",
    "        self.pad = (pad0, pad1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = upfirdn2d(input, self.kernel, up=1,\n",
    "                        down=self.factor, pad=self.pad)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Blur(nn.Module):\n",
    "    def __init__(self, kernel, pad, upsample_factor=1):\n",
    "        super().__init__()\n",
    "\n",
    "        kernel = make_kernel(kernel)\n",
    "\n",
    "        if upsample_factor > 1:\n",
    "            kernel = kernel * (upsample_factor ** 2)\n",
    "\n",
    "        self.register_buffer('kernel', kernel)\n",
    "\n",
    "        self.pad = pad\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = upfirdn2d(input, self.kernel, pad=self.pad)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class EqualizedLinear(nn.Module):\n",
    "    \"\"\"Linear layer with equalized learning rate and custom learning rate multiplier.\"\"\"\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, bias=True, bias_init=0., activation=None,\n",
    "                 gain=1., use_wscale=True, lrmul=1.):\n",
    "        super(EqualizedLinear, self).__init__()\n",
    "\n",
    "        # Equalized learning rate and custom learning rate multiplier.\n",
    "        he_std = gain * in_dim ** (-0.5)  # He init\n",
    "        if use_wscale:\n",
    "            init_std = 1.0 / lrmul\n",
    "            self.w_mul = he_std * lrmul\n",
    "        else:\n",
    "            init_std = he_std / lrmul\n",
    "            self.w_mul = lrmul\n",
    "\n",
    "        self.weight = torch.nn.Parameter(torch.randn(\n",
    "            out_dim, in_dim) * init_std, requires_grad=True)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(\n",
    "                out_dim).fill_(bias_init), requires_grad=True)\n",
    "            self.b_mul = lrmul\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.activation == 'lrelu':  # act='lrelu'\n",
    "            out = F.linear(x, self.weight * self.w_mul)\n",
    "            out = fused_leaky_relu(out, self.bias * self.b_mul)\n",
    "        else:\n",
    "            out = F.linear(x, self.weight * self.w_mul,\n",
    "                           bias=self.bias * self.b_mul)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class EqualizedModConv2d(nn.Module):\n",
    "    def __init__(self, dlatent_size, in_channel, out_channel, kernel,\n",
    "                 up=False, down=False, demodulate=True, resample_kernel=None,\n",
    "                 gain=1., use_wscale=True, lrmul=1.):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super(EqualizedModConv2d, self).__init__()\n",
    "\n",
    "        assert not (up and down)\n",
    "        assert kernel >= 1 and kernel % 2 == 1\n",
    "\n",
    "        if resample_kernel is None:\n",
    "            resample_kernel = [1, 3, 3, 1]\n",
    "\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.up = up\n",
    "        self.down = down\n",
    "        self.demodulate = demodulate\n",
    "        self.kernel = kernel\n",
    "\n",
    "        if up:\n",
    "            factor = 2\n",
    "            p = (len(resample_kernel) - factor) - (kernel - 1)\n",
    "            self.blur = Blur(resample_kernel, pad=(\n",
    "                (p + 1) // 2 + factor - 1, p // 2 + 1), upsample_factor=factor)\n",
    "\n",
    "        if down:\n",
    "            factor = 2\n",
    "            p = (len(resample_kernel) - factor) + (kernel - 1)\n",
    "            self.blur = Blur(resample_kernel, pad=((p + 1) // 2, p // 2))\n",
    "\n",
    "        self.mod = EqualizedLinear(\n",
    "            in_dim=dlatent_size, out_dim=in_channel, bias_init=1.)\n",
    "\n",
    "        he_std = gain * (in_channel * kernel ** 2) ** (-0.5)  # He init\n",
    "        if use_wscale:\n",
    "            init_std = 1.0 / lrmul\n",
    "            self.w_mul = he_std * lrmul\n",
    "        else:\n",
    "            init_std = he_std / lrmul\n",
    "            self.w_mul = lrmul\n",
    "\n",
    "        self.weight = torch.nn.Parameter(\n",
    "            torch.randn(1, out_channel, in_channel, kernel, kernel) * init_std, requires_grad=True)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        batch, in_channel, height, width = x.shape\n",
    "\n",
    "        # Modulate\n",
    "        s = self.mod(y).view(batch, 1, in_channel, 1, 1)\n",
    "        ww = self.w_mul * self.weight * s\n",
    "\n",
    "        # Demodulate\n",
    "        if self.demodulate:\n",
    "            # [BO] Scaling factor.\n",
    "            d = torch.rsqrt(ww.pow(2).sum([2, 3, 4]) + 1e-8)\n",
    "            # [BOIkk] Scale output feature maps.\n",
    "            ww *= d.view(batch, self.out_channel, 1, 1, 1)\n",
    "\n",
    "        weight = ww.view(batch * self.out_channel,\n",
    "                         in_channel, self.kernel, self.kernel)\n",
    "\n",
    "        if self.up:\n",
    "            x = x.view(1, batch * in_channel, height, width)\n",
    "            weight = weight.view(batch, self.out_channel,\n",
    "                                 in_channel, self.kernel, self.kernel)\n",
    "            weight = weight.transpose(1, 2).reshape(batch * in_channel, self.out_channel,\n",
    "                                                    self.kernel, self.kernel)\n",
    "            out = F.conv_transpose2d(\n",
    "                x, weight, padding=0, stride=2, groups=batch)\n",
    "            _, _, height, width = out.shape\n",
    "            out = out.view(batch, self.out_channel, height, width)\n",
    "            out = self.blur(out)\n",
    "        elif self.down:\n",
    "            x = self.blur(x)\n",
    "            _, _, height, width = x.shape\n",
    "            x = x.view(1, batch * in_channel, height, width)\n",
    "            out = F.conv2d(x, weight, padding=0, stride=2, groups=batch)\n",
    "            _, _, height, width = out.shape\n",
    "            out = out.view(batch, self.out_channel, height, width)\n",
    "        else:\n",
    "            x = x.view(1, batch * in_channel, height, width)\n",
    "            out = F.conv2d(x, weight, padding=self.kernel // 2, groups=batch)\n",
    "            _, _, height, width = out.shape\n",
    "            out = out.view(batch, self.out_channel, height, width)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f'{self.__class__.__name__}({self.in_channel}, {self.out_channel}, {self.kernel}, '\n",
    "            f'upsample={self.up}, downsample={self.down})'\n",
    "        )\n",
    "\n",
    "dlatent_size = 512\n",
    "in_channel = 3\n",
    "out_channel = 12\n",
    "kernel = 3\n",
    "conv = EqualizedModConv2d(dlatent_size, in_channel, out_channel, kernel)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 24, 24])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(torch.rand(1, 3, 24, 24), torch.rand(1, 512)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─EqualizedLinear: 1-1                   [-1, 3]                   1,539\n",
      "==========================================================================================\n",
      "Total params: 1,539\n",
      "Trainable params: 1,539\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.01\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "------------------------------------------------------------------------------------------\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─EqualizedLinear: 1-1                   [-1, 3]                   1,539\n",
       "==========================================================================================\n",
       "Total params: 1,539\n",
       "Trainable params: 1,539\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "------------------------------------------------------------------------------------------\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.01\n",
       "Estimated Total Size (MB): 0.01\n",
       "------------------------------------------------------------------------------------------"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(conv, [(3, 24, 24), (512,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 12, 3, 3, 3]), torch.Size([3, 512]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.shape, conv.mod.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_0.3",
   "language": "python",
   "name": "pytorch3d_0.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
