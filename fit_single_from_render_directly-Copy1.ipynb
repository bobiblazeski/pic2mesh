{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torchvision.utils import make_grid\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src.render.mesh_renderer import MeshPointsRenderer\n",
    "from src.models.generator import Generator\n",
    "from src.augment.diffaug import DiffAugment\n",
    "from src.augment.geoaug import GeoAugment\n",
    "from src.callback.image_mesh import ImageMesh\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from src.data.fast_datamodule import FastDataModule\n",
    "from src.data.baseline_dataset import BaselineDataset\n",
    "from src.utilities.operators import make_laplacian\n",
    "\n",
    "def get_img_t(file, config):\n",
    "    img = Image.open(file)\n",
    "    size = config.fast_image_size        \n",
    "    mean = config.fast_image_mean\n",
    "    std = config.fast_image_std\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize([size, size]),            \n",
    "        transforms.Grayscale(),          \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(mean), std=(std)),\n",
    "    ])\n",
    "    return transform(img)[None]\n",
    "\n",
    "file_root = '/home/bobi/Desktop/pic2mesh/data/stan_lee'\n",
    "files = {\n",
    "    'p00': os.path.join(file_root, 'stan_lee_p00.png'),\n",
    "    'p45': os.path.join(file_root, 'stan_lee_p45.png'),\n",
    "    'n45': os.path.join(file_root, 'stan_lee_n45.png'),\n",
    "    'p90': os.path.join(file_root, 'stan_lee_p90.png'),\n",
    "    'n90': os.path.join(file_root, 'stan_lee_n45.png'),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "class RSP(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        self.mean = hparams.fast_image_mean\n",
    "        self.std = hparams.fast_image_std        \n",
    "        self.diffaug = hparams.diffaug_policy\n",
    "        self.G_noise_amp = hparams.G_noise_amp\n",
    "        self.log_render_interval = hparams.log_render_interval\n",
    "        \n",
    "        self.G = Generator(hparams)\n",
    "        \n",
    "        self.Rp00 = MeshPointsRenderer(hparams)\n",
    "        hparams.viewpoint_azimuth = +45\n",
    "        self.Rp45 = MeshPointsRenderer(hparams)\n",
    "        hparams.viewpoint_azimuth = -45\n",
    "        self.Rn45 = MeshPointsRenderer(hparams)\n",
    "        hparams.viewpoint_azimuth = +90\n",
    "        self.Rp90 = MeshPointsRenderer(hparams)\n",
    "        hparams.viewpoint_azimuth = -90\n",
    "        self.Rn90 = MeshPointsRenderer(hparams)\n",
    "        \n",
    "        self.register_buffer('tp00', get_img_t(files['p00'], hparams))\n",
    "        self.register_buffer('tp45', get_img_t(files['p45'], hparams))\n",
    "        self.register_buffer('tn45', get_img_t(files['n45'], hparams))\n",
    "        self.register_buffer('tp90', get_img_t(files['p90'], hparams))\n",
    "        self.register_buffer('tn90', get_img_t(files['n90'], hparams))\n",
    "        \n",
    "        self.ratio =  0.925\n",
    "        #self.blur = transforms.GaussianBlur(17, 3)\n",
    "        self.blur = lambda x: x\n",
    "        \n",
    "        ds = BaselineDataset(hparams)\n",
    "        self.points = nn.Parameter(ds[0][None])\n",
    "        self.register_buffer('colors', torch.ones_like(self.points))\n",
    "        \n",
    "        self.laplacian = make_laplacian(3)\n",
    "        #self.base_laplacian =  0.0062 #torch.abs(self.points - self.laplacian(self.points)).mean()\n",
    "        \n",
    "    def forward(self, baseline):\n",
    "        return self.G(baseline)\n",
    "        \n",
    "    \n",
    "    def laplacian_loss(self, t):\n",
    "#         return torch.relu(torch.abs(t - self.laplacian(t)).mean() \n",
    "#                           - self.base_laplacian)\n",
    "        #return torch.abs(t - self.laplacian(t)).mean()\n",
    "        \n",
    "        full_loss = F.l1_loss(t, self.laplacian(t.detach()))\n",
    "        half = F.avg_pool2d(t, 2)\n",
    "        #half_loss = F.l1_loss(half, self.laplacian(half.detach()))\n",
    "        #F.avg_pool2d(t, )\n",
    "        return full_loss# + half_loss\n",
    "        #return torch.abs(t - self.laplacian(t)).max() \n",
    "    \n",
    "    def render(self, points, colors, mean=None, std=None):        \n",
    "        return {\n",
    "            'p00': self.Rp00(points, colors, mean, std),\n",
    "            'p45': self.Rp45(points, colors, mean, std),\n",
    "            'n45': self.Rn45(points, colors, mean, std),\n",
    "            'p90': self.Rp90(points, colors, mean, std),\n",
    "            'n90': self.Rn90(points, colors, mean, std),\n",
    "        }\n",
    "    \n",
    "    def loss(self, renders):\n",
    "        bs = renders['p00'].size(0)\n",
    "        lp00 = F.mse_loss(\n",
    "            self.blur(renders['p00']), \n",
    "            self.blur(self.tp00.expand(bs, -1, -1 , -1))\n",
    "        )\n",
    "        lp45 = F.mse_loss(\n",
    "            self.blur(renders['p45']),\n",
    "            self.blur(self.tp45.expand(bs, -1, -1 , -1))\n",
    "        )        \n",
    "        ln45 = F.mse_loss(\n",
    "            self.blur(renders['n45']), \n",
    "            self.blur(self.tn45.expand(bs, -1, -1 , -1))\n",
    "        )\n",
    "        lp90 = F.mse_loss(\n",
    "            self.blur(renders['p90']), \n",
    "            self.blur(self.tp90.expand(bs, -1, -1 , -1))\n",
    "        )\n",
    "        ln90 = F.mse_loss(\n",
    "            self.blur(renders['n90']), \n",
    "            self.blur(self.tn90.expand(bs, -1, -1 , -1))\n",
    "        )                \n",
    "        \n",
    "        self.log(f\"loss/lp00\", lp00.item())\n",
    "        self.log(f\"loss/lp45\", lp45.item())\n",
    "        self.log(f\"loss/ln45\", ln45.item())\n",
    "        self.log(f\"loss/lp90\", lp90.item())\n",
    "        self.log(f\"loss/ln90\", ln90.item())        \n",
    "        render_loss = lp00 + lp45 + ln45 + lp90 + ln90        \n",
    "        self.log(f\"loss/render_loss\", render_loss.item())\n",
    "        return render_loss\n",
    "    \n",
    "    def log_renders(self, points, colors, batch_idx):\n",
    "        if batch_idx % self.log_render_interval == 0:\n",
    "            renders = self.render(points.detach(), colors.detach())            \n",
    "            stacked = torch.cat(list(renders.values()))\n",
    "            grid = make_grid(tensor=stacked, nrow = len(renders))            \n",
    "            self.logger.experiment.add_image('renders', grid, self.global_step)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #baseline= batch\n",
    "        points, colors = self.points, self.colors\n",
    "        laplacian_loss = self.laplacian_loss(points)\n",
    "        self.log(f\"loss/laplacian_loss\", laplacian_loss.item())\n",
    "        #print(laplacian_loss.item())\n",
    "        self.log_renders(points, colors, batch_idx)\n",
    "        renders = self.render(points, colors, self.mean, self.std)        \n",
    "        loss = self.loss(renders) + laplacian_loss\n",
    "        self.log(f\"loss/loss\", loss.item())\n",
    "        return loss \n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam([self.points], lr=0.0003)\n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        self.ratio = min(self.ratio + 0.025, 1) \n",
    "    \n",
    "from src.config import get_parser\n",
    "\n",
    "config = get_parser().parse_args(args=[])\n",
    "config.fast_baseline_size = 64\n",
    "config.fast_image_size = 64\n",
    "config.viewpoint_distance = 3.25\n",
    "config.G_noise_amp = 0.001\n",
    "rsp = RSP(config)\n",
    "#rsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.data.fast_datamodule.FastDataModule at 0x7feb32bd3af0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.fast_batch_size = 1\n",
    "dm = FastDataModule(config, BaselineDataset)    \n",
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import trimesh\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src.utilities.util import (\n",
    "    grid_to_list,\n",
    "    make_faces,\n",
    ")\n",
    "\n",
    "class ImageMesh(pl.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, opt):\n",
    "        super().__init__()\n",
    "        self.num_samples = opt.log_grid_samples\n",
    "        self.nrow = opt.log_grid_rows\n",
    "        self.padding = opt.log_grid_padding                \n",
    "        self.pad_value = opt.log_pad_value        \n",
    "        self.log_batch_interval = opt.log_batch_interval\n",
    "        self.faces = None\n",
    "        \n",
    "        \n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\n",
    "        # show images only every log_batch_interval batches\n",
    "        if (trainer.batch_idx % self.log_batch_interval) != 0:  # type: ignore[attr-defined]\n",
    "            return\n",
    "        batch = next(iter(trainer.datamodule.train_dataloader()))\n",
    "        \n",
    "        # generate images\n",
    "        with torch.no_grad():\n",
    "            pl_module.eval()\n",
    "            baseline= batch.to(pl_module.device)\n",
    "            points = pl_module.points\n",
    "            pl_module.train()\n",
    "\n",
    "            try:            \n",
    "                if self.faces is None:\n",
    "                    self.faces = make_faces(points.size(-2), points.size(-1))\n",
    "                vertices = grid_to_list(points)[0].cpu().numpy()\n",
    "                mesh = trimesh.Trimesh(vertices=vertices, faces=self.faces)\n",
    "                mesh_dir = os.path.join(trainer.log_dir, 'mesh')\n",
    "                if not os.path.exists(mesh_dir):\n",
    "                    os.makedirs(mesh_dir)\n",
    "                file_path = os.path.join(mesh_dir, f'mesh_{trainer.current_epoch}_{trainer.global_step}.stl')\n",
    "                mesh.export(file_path)                     \n",
    "            except:\n",
    "                print('Exception', points.shape)\n",
    "                pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | G         | Generator          | 1.0 M \n",
      "1 | Rp00      | MeshPointsRenderer | 0     \n",
      "2 | Rp45      | MeshPointsRenderer | 0     \n",
      "3 | Rn45      | MeshPointsRenderer | 0     \n",
      "4 | Rp90      | MeshPointsRenderer | 0     \n",
      "5 | Rn90      | MeshPointsRenderer | 0     \n",
      "6 | laplacian | Conv2d             | 225   \n",
      "-------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "225       Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.226     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afd888a72cc4c449ee80164dd35e3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, max_epochs=100, progress_bar_refresh_rate=20,\n",
    "                     terminate_on_nan=True, callbacks=[ImageMesh(config)])\n",
    "trainer.fit(rsp, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = nn.Conv2d(3, 3, 3, stride=1, padding=1, bias=False)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_laplacian():\n",
    "    hood = [[0.125, 0.125, 0.125],\n",
    "            [0.125, 0.000, 0.125],\n",
    "            [0.125, 0.125, 0.125],]\n",
    "\n",
    "    zeros = [[0.000, 0.000, 0.000],\n",
    "             [0.000, 0.000, 0.000],\n",
    "             [0.000, 0.000, 0.000],]\n",
    "\n",
    "    weights = torch.tensor([\n",
    "        [hood, zeros, zeros],\n",
    "        [zeros, hood, zeros],\n",
    "        [zeros, zeros, hood],\n",
    "    ])\n",
    "    res = nn.Conv2d(3, 3, 3, stride=1, padding=1, \n",
    "        bias=False, padding_mode='replicate')\n",
    "    res.requires_grad_(False)\n",
    "    res.weight.data = weights\n",
    "    return res\n",
    "\n",
    "laplacian = make_laplacian()\n",
    "laplacian.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = rsp\n",
    "torch.abs(self.points - self.laplacian(self.points)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "from src.utilities.util import (\n",
    "    grid_to_list,\n",
    "    make_faces,\n",
    ")\n",
    "sz = 64\n",
    "config.fast_baseline_size = sz\n",
    "config.G_noise_amp = 0.001\n",
    "faces = make_faces(sz, sz)\n",
    "ds = BaselineDataset(config)\n",
    "base_vert = ds[0][None]\n",
    "smooth_vert = laplacian(base_vert)\n",
    "\n",
    "mesh = trimesh.Trimesh(vertices=grid_to_list(base_vert)[0], faces=faces)\n",
    "mesh.export('./base.stl')\n",
    "\n",
    "\n",
    "mesh = trimesh.Trimesh(vertices=grid_to_list(smooth_vert)[0], faces=faces)\n",
    "mesh.export('./smooth.stl');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_to_list(base_vert)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.abs(base_vert -smooth_vert).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.avg_pool2d(torch.rand(1, 3, 8, 8), 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 2 3 4 5\n",
    "# 2\n",
    "# 3\n",
    "# 4\n",
    "# 5\n",
    "# 16 \n",
    "#  8\n",
    "# 16 * x + 8 * 2 * x =  1\n",
    "# 32x  = 1\n",
    "# x= 0.03125\n",
    "#x= 0.0625\n",
    "0.03125 * 16 +  0.0625 * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 5, 5]) torch.Size([3, 3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(res.weight.data.shape, weights.shape)\n",
    "res.weight.data = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 8, 8])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res(torch.rand(1, 3, 8, 8)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_0.3",
   "language": "python",
   "name": "pytorch3d_0.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
