{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GAN(\n",
       "  (G): Generator(\n",
       "    (points): SinGenerator(\n",
       "      (trunk): Sequential(\n",
       "        (head): ConvBlock(\n",
       "          (conv): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "        (main): Sequential(\n",
       "          (b0): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "          )\n",
       "          (b1): ConvBlock(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "          )\n",
       "          (b2): ConvBlock(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (points): Sequential(\n",
       "        (0): Conv2d(256, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): Tanh()\n",
       "      )\n",
       "      (ratio): Sequential(\n",
       "        (0): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (D): Discriminator(\n",
       "    (encoder): Encoder(\n",
       "      (b0): DownBlock(\n",
       "        (conv): ConvBlock(\n",
       "          (conv): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "        (main): Sequential(\n",
       "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (conv): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (b1): DownBlock(\n",
       "        (conv): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "        (main): Sequential(\n",
       "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (conv): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (b2): DownBlock(\n",
       "        (conv): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "        (main): Sequential(\n",
       "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (conv): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): Classifier(\n",
       "      (conv): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (b0): UpBlock(\n",
       "        (conv): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "        (main): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "      )\n",
       "      (b1): UpBlock(\n",
       "        (conv): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "        (main): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "      )\n",
       "      (b2): UpBlock(\n",
       "        (conv): ConvBlock(\n",
       "          (conv): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "        (main): ConvBlock(\n",
       "          (conv): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.2)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (R): MeshPointsRenderer()\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torchvision.utils import make_grid\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src.render.mesh_renderer import MeshPointsRenderer\n",
    "from src.models.discriminator import Discriminator\n",
    "from src.models.generator import Generator\n",
    "from src.augment.diffaug import DiffAugment\n",
    "from src.augment.geoaug import GeoAugment\n",
    "from src.lpips import PerceptualLoss\n",
    "from src.callback.image_mesh import ImageMesh\n",
    "\n",
    "def train_d(labels, decodings=None, reals=None):\n",
    "    \"\"\"Train function of discriminator\"\"\"    \n",
    "    if reals is not None:\n",
    "        d_adv_r = F.relu(torch.rand_like(labels) * 0.2 + 0.8 -  labels).mean()        \n",
    "        d_prcp = F.l1_loss(decodings, reals)\n",
    "        log = {'d_adv_r': d_adv_r.item(), 'd_prcp': d_prcp.item()}\n",
    "        loss = d_adv_r + d_prcp\n",
    "    else:        \n",
    "        d_advr_f = F.relu(torch.rand_like(labels) * 0.2 + 0.8 + labels).mean()\n",
    "        log = {'d_advr_f': d_advr_f.item()}\n",
    "        loss = d_advr_f\n",
    "    return loss, log\n",
    "    \n",
    "    \n",
    "class GAN(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        #self.automatic_optimization = False\n",
    "        self.mean = hparams.fast_image_mean\n",
    "        self.std = hparams.fast_image_std        \n",
    "        self.diffaug = hparams.diffaug_policy\n",
    "        self.G_noise_amp = hparams.G_noise_amp\n",
    "        self.log_render_interval = hparams.log_render_interval\n",
    "        \n",
    "        self.G = Generator(hparams)\n",
    "        self.D = Discriminator(hparams)                \n",
    "        self.R = MeshPointsRenderer(hparams)                 \n",
    "        #self.perceptual = PerceptualLoss(model='net-lin', net='squeeze')\n",
    "     \n",
    "    def forward(self, outline):\n",
    "        return self.G(outline)\n",
    "    \n",
    "    def reconstruction(self, points, outline):        \n",
    "        pts = F.avg_pool2d(points, points.size(-1) // outline.size(-1))\n",
    "        return F.mse_loss(pts, outline) / pts.size(0)\n",
    "    \n",
    "    def train_generator(self, points, outline, renders):\n",
    "        labels, _ = self.D(renders, False)\n",
    "        g_adv = -labels.mean()\n",
    "        g_rcn = self.reconstruction(points, outline)\n",
    "        self.log(f\"loss/g_adv\", g_adv.item())\n",
    "        self.log(f\"loss/g_rcn\", g_rcn.item())\n",
    "        return g_adv #+ g_rcn\n",
    "    \n",
    "    def train_discriminator(self, reals, renders):\n",
    "        # Train with reals\n",
    "        labels, decodings = self.D(reals, True)\n",
    "        loss_r, log = train_d(labels, decodings, reals)            \n",
    "        for key in log.keys(): self.log(f\"loss/{key}\", log[key])\n",
    "        # Train with renders\n",
    "        labels, _ = self.D(renders.detach(), False)\n",
    "        loss_f, log = train_d(labels)\n",
    "        for key in log.keys(): self.log(f\"loss/{key}\", log[key])            \n",
    "        return loss_r + loss_f\n",
    "    \n",
    "    def log_renders(self, points, colors, batch_idx):\n",
    "        if batch_idx % self.log_render_interval == 0:\n",
    "            renders = self.R(points.detach(), colors.detach())\n",
    "            grid = make_grid(tensor=renders, nrow = gan.hparams.log_grid_rows)            \n",
    "            self.logger.experiment.add_image('renders', grid, self.global_step)\n",
    "            \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):        \n",
    "        reals, outline, baseline = batch['image'], batch['outline'], batch['baseline']\n",
    "        #with torch.autograd.detect_anomaly():\n",
    "        noise_o =  torch.randn_like(outline) * self.G_noise_amp\n",
    "        noise_b =  torch.randn_like(baseline) * self.G_noise_amp\n",
    "        points, colors = self.G(baseline + noise_b, outline + noise_o)\n",
    "        self.log_renders(points, colors, batch_idx)        \n",
    "        renders = self.R(points, colors, self.mean, self.std)\n",
    "#         print(points.shape, batch['image'].shape, \n",
    "#               batch['outline'].shape, renders.shape)\n",
    "#         raise 'Error'\n",
    "        #reals = DiffAugment(reals, policy=self.diffaug)\n",
    "        #renders = DiffAugment(renders, policy=self.diffaug)         \n",
    "        if optimizer_idx == 0:            \n",
    "            return self.train_discriminator(reals, renders)        \n",
    "        if optimizer_idx == 1:            \n",
    "            return self.train_generator(points, outline, renders)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        lr, betas = 0.0001, (0.5, 0.999)\n",
    "        opt_d = Adam(self.D.parameters(), lr=lr, betas=betas)\n",
    "        opt_g = Adam(self.G.parameters(),  lr=lr, betas=betas)\n",
    "        return [opt_d, opt_g], []\n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        self.ratio -= 0.01 \n",
    "    \n",
    "from src.config import get_parser\n",
    "\n",
    "config = get_parser().parse_args(args=[])   \n",
    "\n",
    "config.log_batch_interval = 100\n",
    "config.fast_outline_size =  64\n",
    "config.fast_baseline_size =  256\n",
    "config.fast_image_size = 128\n",
    "config.fast_batch_size = 8\n",
    "config.raster_faces_per_pixel = 4\n",
    "config.G_noise_amp = 0.005 #0.002\n",
    "config.geoaug_policy = 'scaling'\n",
    "gan = GAN(config)\n",
    "gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.data.fast_datamodule.FastDataModule at 0x7f0ef40dff40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data.fast_datamodule import FastDataModule\n",
    "from src.data.render_dataset import RenderDataset\n",
    "\n",
    "dm = FastDataModule(config, RenderDataset)    \n",
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type               | Params\n",
      "--------------------------------------------\n",
      "0 | G    | Generator          | 1.0 M \n",
      "1 | D    | Discriminator      | 1.5 M \n",
      "2 | R    | MeshPointsRenderer | 0     \n",
      "--------------------------------------------\n",
      "2.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 M     Total params\n",
      "10.105    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b64f65ac534b2ead3eb44fb68e2409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bobi/miniconda3/envs/pytorch3d/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, max_epochs=100, progress_bar_refresh_rate=20,\n",
    "                     terminate_on_nan=True, callbacks=[ImageMesh(config)])\n",
    "trainer.fit(gan, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_0.3",
   "language": "python",
   "name": "pytorch3d_0.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
