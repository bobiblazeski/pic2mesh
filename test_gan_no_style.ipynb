{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src.config import get_parser\n",
    "from src.models.gan import GAN\n",
    "from src.callback import LogExportCallback\n",
    "from src.data.masked_datamodule import MaskedDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAN(\n",
       "  (G): Generator(\n",
       "    (head): ConvBlock(\n",
       "      (conv): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (body): Sequential(\n",
       "      (b1): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b2): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b3): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (tail): Sequential(\n",
       "      (0): Conv2d(256, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (D): Discriminator(\n",
       "    (model): Sequential(\n",
       "      (b0): ConvBlock(\n",
       "        (conv): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b1): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b2): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b3): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (linear): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (R): Renderer()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src.models.discriminator import Discriminator\n",
    "from src.models.generator import Generator\n",
    "from src.renderer import Renderer\n",
    "\n",
    "class GAN(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        self.automatic_optimization = False\n",
    "        self.mean = sum(hparams.image_mean) / len(hparams.image_mean)\n",
    "        self.std = sum(hparams.image_std) / len(hparams.image_std)\n",
    "        \n",
    "        self.G = Generator(hparams)\n",
    "        self.D = Discriminator(hparams)        \n",
    "        # Renderer requires device, created in .to() step\n",
    "        self.R = Renderer(hparams)\n",
    "        \n",
    "     \n",
    "    def forward(self, shape, style):\n",
    "        return self.G(shape, style)\n",
    "    \n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.mse_loss(y_hat, y)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):        \n",
    "        img_patch = batch['img_patch']\n",
    "        points =  batch['points']\n",
    "        normals = batch['normals']            \n",
    "        bs = img_patch.size(0)\n",
    "        \n",
    "        self.R.setup(points.device)\n",
    "        \n",
    "        # train generator\n",
    "        if optimizer_idx == 0:            \n",
    "            vertices = self.G(points)            \n",
    "            renders =  self.R(vertices).permute(0, 3, 1, 2)             \n",
    "            renders = (renders - self.mean) / self.std\n",
    "\n",
    "            # ground truth result (ie: all fake)\n",
    "            # put on GPU because we created this tensor inside training_loop\n",
    "            valid = torch.ones(bs, 1).type_as(points)            \n",
    "           \n",
    "            g_loss = self.adversarial_loss(self.D(renders), valid)\n",
    "            tqdm_dict = {'g_loss': g_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': g_loss,                \n",
    "            })\n",
    "            self.log(\"loss/g_loss\", g_loss, on_epoch=True, prog_bar=True)\n",
    "            return output\n",
    "\n",
    "        # train discriminator\n",
    "        if optimizer_idx == 1:\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "\n",
    "            # how well can it label as real?\n",
    "            valid = torch.ones(bs, 1).type_as(points)         \n",
    "\n",
    "            real_loss = self.adversarial_loss(self.D(imgs), valid)\n",
    "\n",
    "            # how well can it label as fake?\n",
    "            fake = torch.zeros(imgs.size(0), 1).type_as(points)            \n",
    "                        \n",
    "            vertices = self.G(points)            \n",
    "            renders =  self.R(vertices).permute(0, 3, 1, 2)           \n",
    "            renders = (renders - self.mean) / self.std\n",
    "\n",
    "            fake_loss = self.adversarial_loss(\n",
    "                self.D(renders.detach()), fake)\n",
    "\n",
    "            # discriminator loss is the average of these\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            tqdm_dict = {'d_loss': d_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': d_loss,                \n",
    "            })\n",
    "            self.log(\"loss/d_loss\", d_loss, on_step=True, on_epoch=True, prog_bar=True)            \n",
    "            return output\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        lr_g = self.hparams.lr_g\n",
    "        lr_d = self.hparams.lr_d\n",
    "        b1 = self.hparams.beta1\n",
    "        b2 = self.hparams.beta2      \n",
    "        opt_g = torch.optim.Adam(self.G.parameters(), \n",
    "                                 lr=lr_g, betas=(b1, b2))\n",
    "        opt_d = torch.optim.Adam(self.D.parameters(), \n",
    "                                 lr=lr_d, betas=(b1, b2))\n",
    "        return [opt_g, opt_d], []\n",
    "    \n",
    "config = get_parser().parse_args(args=[])\n",
    "#config.batch_size = 8\n",
    "model = GAN(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.data.masked_datamodule.MaskedDataModule at 0x7fab591b9dc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = MaskedDataModule(config)\n",
    "dm.setup()\n",
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type          | Params\n",
      "---------------------------------------\n",
      "0 | G    | Generator     | 1.8 M \n",
      "1 | D    | Discriminator | 1.8 M \n",
      "2 | R    | Renderer      | 0     \n",
      "---------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.264    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ba95076af3436d91f6461d322c05f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, max_epochs=5, progress_bar_refresh_rate=20, \n",
    "                     callbacks=[LogExportCallback(config)])\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_0.3",
   "language": "python",
   "name": "pytorch3d_0.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
