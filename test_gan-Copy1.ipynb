{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src.config import get_parser\n",
    "from src.models.gan import GAN\n",
    "\n",
    "from src.data.masked_datamodule import MaskedDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAN(\n",
       "  (G): Generator(\n",
       "    (head): ModConvLayer(\n",
       "      (conv): EqualizedModConv2d(6, 128, 3, upsample=False, downsample=False)\n",
       "    )\n",
       "    (body): Sequential(\n",
       "      (b1): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b2): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b3): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (tail): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (D): Discriminator(\n",
       "    (model): Sequential(\n",
       "      (b0): ConvBlock(\n",
       "        (conv): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b1): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b2): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b3): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (reparam): Linear(in_features=128, out_features=2, bias=False)\n",
       "  )\n",
       "  (S): Stylist(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ReLU()\n",
       "      (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (13): ReLU()\n",
       "      (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (17): ReLU()\n",
       "      (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (20): ReLU()\n",
       "      (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (cont): Linear(in_features=512, out_features=128, bias=True)\n",
       "  )\n",
       "  (R): Renderer()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src.models.discriminator import Discriminator\n",
    "from src.models.generator import Generator\n",
    "from src.models.stylist import Stylist\n",
    "from src.renderer import Renderer\n",
    "\n",
    "class GAN(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        self.automatic_optimization = False\n",
    "        self.mean = sum(hparams.image_mean) / len(hparams.image_mean)\n",
    "        self.std = sum(hparams.image_std) / len(hparams.image_std)\n",
    "        \n",
    "        self.G = Generator(hparams)\n",
    "        self.D = Discriminator(hparams)\n",
    "        self.S = Stylist(hparams)\n",
    "        # Renderer requires device, created in .to() step\n",
    "        self.R = Renderer(hparams)\n",
    "        \n",
    "     \n",
    "    def forward(self, shape, style):\n",
    "        return self.G(shape, style)\n",
    "    \n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.mse_loss(y_hat, y)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        style_img = batch['style_img']\n",
    "        img_patch = batch['img_patch']\n",
    "        points =  batch['points']\n",
    "        normals = batch['normals']            \n",
    "        bs = style_img.size(0)\n",
    "        \n",
    "        self.R.setup(points.device)\n",
    "        \n",
    "        # train generator\n",
    "        if optimizer_idx == 0:\n",
    "            style = self.S(style_img)\n",
    "            vertices = self.G(points, normals, style)            \n",
    "            renders =  self.R(vertices).permute(0, 3, 1, 2)             \n",
    "            renders = (renders - self.mean) / self.std\n",
    "\n",
    "            # ground truth result (ie: all fake)\n",
    "            # put on GPU because we created this tensor inside training_loop\n",
    "            valid = torch.ones(bs, 1).type_as(style_img)            \n",
    "\n",
    "            # adversarial loss is binary cross-entropy\n",
    "            g_loss = self.adversarial_loss(self.D(renders), valid)\n",
    "            tqdm_dict = {'g_loss': g_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': g_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "            return output\n",
    "\n",
    "        # train discriminator\n",
    "        if optimizer_idx == 1:\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "\n",
    "            # how well can it label as real?\n",
    "            valid = torch.ones(bs, 1).type_as(style_img)         \n",
    "\n",
    "            real_loss = self.adversarial_loss(self.D(imgs), valid)\n",
    "\n",
    "            # how well can it label as fake?\n",
    "            fake = torch.zeros(imgs.size(0), 1)\n",
    "            fake = fake.type_as(imgs)\n",
    "            \n",
    "            style = self.S(style_img)\n",
    "            vertices = self.G(points, normals, style)            \n",
    "            renders =  self.R(vertices).permute(0, 3, 1, 2)           \n",
    "            renders = (renders - self.mean) / self.std\n",
    "\n",
    "            fake_loss = self.adversarial_loss(\n",
    "                self.D(renders.detach()), fake)\n",
    "\n",
    "            # discriminator loss is the average of these\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            tqdm_dict = {'d_loss': d_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': d_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "            return output\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        lr_g = self.hparams.lr_g\n",
    "        lr_d = self.hparams.lr_d\n",
    "        b1 = self.hparams.beta1\n",
    "        b2 = self.hparams.beta2      \n",
    "        opt_gs = torch.optim.Adam(list(self.G.parameters()) \n",
    "                                 + list(self.S.parameters()), \n",
    "                                 lr=lr_g, betas=(b1, b2))\n",
    "        opt_d = torch.optim.Adam(self.D.parameters(), \n",
    "                                 lr=lr_d, betas=(b1, b2))\n",
    "        return [opt_gs, opt_d], []\n",
    "    \n",
    "config = get_parser().parse_args(args=[])\n",
    "config.batch_size = 4\n",
    "model = GAN(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.data.masked_datamodule.MaskedDataModule at 0x7fc230f02d30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = MaskedDataModule(config)\n",
    "dm.setup()\n",
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type          | Params\n",
      "---------------------------------------\n",
      "0 | G    | Generator     | 598 K \n",
      "1 | D    | Discriminator | 447 K \n",
      "2 | S    | Stylist       | 4.6 M \n",
      "3 | R    | Renderer      | 0     \n",
      "---------------------------------------\n",
      "5.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 M     Total params\n",
      "22.462    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57599b249fc43de9fecbbfe36d01362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[4, 3, -1]' is invalid for input of size 134217728",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-05f397feeab1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar_refresh_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# dispath `start_training` or `start_testing` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_or_test_or_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                     \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m# ------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# when returning -1 from train_step, we end epoch early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                         self._curr_step_result = self.training_step(\n\u001b[0m\u001b[1;32m    659\u001b[0m                             \u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                         )\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, split_batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e6fa467eed92>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx, optimizer_idx)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mvertices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mrenders\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mrenders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrenders\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/pic2mesh/src/renderer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, points, normals, translate)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (b, 3, w, h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         rgb = torch.ones((bs, points.size(1), 3), \n\u001b[1;32m     86\u001b[0m                          device=points.device) * self.max_brightness\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[4, 3, -1]' is invalid for input of size 134217728"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, max_epochs=5, progress_bar_refresh_rate=20)\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "style_img torch.Size([4, 1, 192, 192])\n",
      "img_patch torch.Size([4, 1, 256, 256])\n",
      "points torch.Size([4, 3, 512, 512])\n",
      "normals torch.Size([4, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dm.train_dataloader()))\n",
    "for key in batch.keys():\n",
    "    print(key, batch[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 512, 6, 6]           --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 192, 192]        640\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 64, 192, 192]        128\n",
      "|    └─ReLU: 2-3                         [-1, 64, 192, 192]        --\n",
      "|    └─MaxPool2d: 2-4                    [-1, 64, 96, 96]          --\n",
      "|    └─Conv2d: 2-5                       [-1, 128, 96, 96]         73,856\n",
      "|    └─BatchNorm2d: 2-6                  [-1, 128, 96, 96]         256\n",
      "|    └─ReLU: 2-7                         [-1, 128, 96, 96]         --\n",
      "|    └─MaxPool2d: 2-8                    [-1, 128, 48, 48]         --\n",
      "|    └─Conv2d: 2-9                       [-1, 256, 48, 48]         295,168\n",
      "|    └─BatchNorm2d: 2-10                 [-1, 256, 48, 48]         512\n",
      "|    └─ReLU: 2-11                        [-1, 256, 48, 48]         --\n",
      "|    └─Conv2d: 2-12                      [-1, 256, 48, 48]         590,080\n",
      "|    └─BatchNorm2d: 2-13                 [-1, 256, 48, 48]         512\n",
      "|    └─ReLU: 2-14                        [-1, 256, 48, 48]         --\n",
      "|    └─MaxPool2d: 2-15                   [-1, 256, 24, 24]         --\n",
      "|    └─Conv2d: 2-16                      [-1, 512, 24, 24]         1,180,160\n",
      "|    └─BatchNorm2d: 2-17                 [-1, 512, 24, 24]         1,024\n",
      "|    └─ReLU: 2-18                        [-1, 512, 24, 24]         --\n",
      "|    └─Conv2d: 2-19                      [-1, 512, 24, 24]         2,359,808\n",
      "|    └─BatchNorm2d: 2-20                 [-1, 512, 24, 24]         1,024\n",
      "|    └─ReLU: 2-21                        [-1, 512, 24, 24]         --\n",
      "|    └─MaxPool2d: 2-22                   [-1, 512, 12, 12]         --\n",
      "|    └─Conv2d: 2-23                      [-1, 512, 12, 12]         2,359,808\n",
      "|    └─BatchNorm2d: 2-24                 [-1, 512, 12, 12]         1,024\n",
      "|    └─ReLU: 2-25                        [-1, 512, 12, 12]         --\n",
      "|    └─Conv2d: 2-26                      [-1, 512, 12, 12]         2,359,808\n",
      "|    └─BatchNorm2d: 2-27                 [-1, 512, 12, 12]         1,024\n",
      "|    └─ReLU: 2-28                        [-1, 512, 12, 12]         --\n",
      "|    └─MaxPool2d: 2-29                   [-1, 512, 6, 6]           --\n",
      "├─Linear: 1-2                            [-1, 128]                 65,664\n",
      "==========================================================================================\n",
      "Total params: 9,290,496\n",
      "Trainable params: 9,290,496\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 5.47\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.14\n",
      "Forward/backward pass size (MB): 83.25\n",
      "Params size (MB): 35.44\n",
      "Estimated Total Size (MB): 118.83\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model.S, (1, 192, 192));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 512, 12, 12]         --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 192, 192]        640\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 64, 192, 192]        128\n",
      "|    └─ReLU: 2-3                         [-1, 64, 192, 192]        --\n",
      "|    └─MaxPool2d: 2-4                    [-1, 64, 96, 96]          --\n",
      "|    └─Conv2d: 2-5                       [-1, 128, 96, 96]         73,856\n",
      "|    └─BatchNorm2d: 2-6                  [-1, 128, 96, 96]         256\n",
      "|    └─ReLU: 2-7                         [-1, 128, 96, 96]         --\n",
      "|    └─MaxPool2d: 2-8                    [-1, 128, 48, 48]         --\n",
      "|    └─Conv2d: 2-9                       [-1, 256, 48, 48]         295,168\n",
      "|    └─BatchNorm2d: 2-10                 [-1, 256, 48, 48]         512\n",
      "|    └─ReLU: 2-11                        [-1, 256, 48, 48]         --\n",
      "|    └─Conv2d: 2-12                      [-1, 256, 48, 48]         590,080\n",
      "|    └─BatchNorm2d: 2-13                 [-1, 256, 48, 48]         512\n",
      "|    └─ReLU: 2-14                        [-1, 256, 48, 48]         --\n",
      "|    └─MaxPool2d: 2-15                   [-1, 256, 24, 24]         --\n",
      "|    └─Conv2d: 2-16                      [-1, 512, 24, 24]         1,180,160\n",
      "|    └─BatchNorm2d: 2-17                 [-1, 512, 24, 24]         1,024\n",
      "|    └─ReLU: 2-18                        [-1, 512, 24, 24]         --\n",
      "|    └─Conv2d: 2-19                      [-1, 512, 24, 24]         2,359,808\n",
      "|    └─BatchNorm2d: 2-20                 [-1, 512, 24, 24]         1,024\n",
      "|    └─ReLU: 2-21                        [-1, 512, 24, 24]         --\n",
      "|    └─MaxPool2d: 2-22                   [-1, 512, 12, 12]         --\n",
      "├─Linear: 1-2                            [-1, 128]                 65,664\n",
      "==========================================================================================\n",
      "Total params: 4,568,832\n",
      "Trainable params: 4,568,832\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 4.78\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.14\n",
      "Forward/backward pass size (MB): 81.00\n",
      "Params size (MB): 17.43\n",
      "Estimated Total Size (MB): 98.57\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model.S, (1, 192, 192));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─ModConvLayer: 1-1                      [-1, 128, 512, 512]       --\n",
      "|    └─EqualizedModConv2d: 2-1           [-1, 128, 512, 512]       --\n",
      "|    |    └─EqualizedLinear: 3-1         [-1, 6]                   774\n",
      "├─Sequential: 1-2                        [-1, 128, 512, 512]       --\n",
      "|    └─ConvBlock: 2-2                    [-1, 128, 512, 512]       --\n",
      "|    |    └─Conv2d: 3-2                  [-1, 128, 512, 512]       147,584\n",
      "|    |    └─BatchNorm2d: 3-3             [-1, 128, 512, 512]       256\n",
      "|    |    └─LeakyReLU: 3-4               [-1, 128, 512, 512]       --\n",
      "|    └─ConvBlock: 2-3                    [-1, 128, 512, 512]       --\n",
      "|    |    └─Conv2d: 3-5                  [-1, 128, 512, 512]       147,584\n",
      "|    |    └─BatchNorm2d: 3-6             [-1, 128, 512, 512]       256\n",
      "|    |    └─LeakyReLU: 3-7               [-1, 128, 512, 512]       --\n",
      "|    └─ConvBlock: 2-4                    [-1, 128, 512, 512]       --\n",
      "|    |    └─Conv2d: 3-8                  [-1, 128, 512, 512]       147,584\n",
      "|    |    └─BatchNorm2d: 3-9             [-1, 128, 512, 512]       256\n",
      "|    |    └─LeakyReLU: 3-10              [-1, 128, 512, 512]       --\n",
      "├─Sequential: 1-3                        [-1, 128, 512, 512]       --\n",
      "|    └─Conv2d: 2-5                       [-1, 128, 512, 512]       147,584\n",
      "|    └─Tanh: 2-6                         [-1, 128, 512, 512]       --\n",
      "==========================================================================================\n",
      "Total params: 591,878\n",
      "Trainable params: 591,878\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 156.43\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 6.00\n",
      "Forward/backward pass size (MB): 1792.00\n",
      "Params size (MB): 2.26\n",
      "Estimated Total Size (MB): 1800.26\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model.G, [(3, 512, 512), (3, 512, 512), (config.dlatent_size,)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 128]                 --\n",
      "|    └─ConvBlock: 2-1                    [-1, 128, 512, 512]       --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 128, 512, 512]       3,584\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 128, 512, 512]       256\n",
      "|    |    └─LeakyReLU: 3-3               [-1, 128, 512, 512]       --\n",
      "|    └─ConvBlock: 2-2                    [-1, 128, 512, 512]       --\n",
      "|    |    └─Conv2d: 3-4                  [-1, 128, 512, 512]       147,584\n",
      "|    |    └─BatchNorm2d: 3-5             [-1, 128, 512, 512]       256\n",
      "|    |    └─LeakyReLU: 3-6               [-1, 128, 512, 512]       --\n",
      "|    └─ConvBlock: 2-3                    [-1, 128, 512, 512]       --\n",
      "|    |    └─Conv2d: 3-7                  [-1, 128, 512, 512]       147,584\n",
      "|    |    └─BatchNorm2d: 3-8             [-1, 128, 512, 512]       256\n",
      "|    |    └─LeakyReLU: 3-9               [-1, 128, 512, 512]       --\n",
      "|    └─ConvBlock: 2-4                    [-1, 128, 512, 512]       --\n",
      "|    |    └─Conv2d: 3-10                 [-1, 128, 512, 512]       147,584\n",
      "|    |    └─BatchNorm2d: 3-11            [-1, 128, 512, 512]       256\n",
      "|    |    └─LeakyReLU: 3-12              [-1, 128, 512, 512]       --\n",
      "|    └─AdaptiveAvgPool2d: 2-5            [-1, 128, 1, 1]           --\n",
      "|    └─Flatten: 2-6                      [-1, 128]                 --\n",
      "├─Linear: 1-2                            [-1, 32]                  4,128\n",
      "├─Linear: 1-3                            [-1, 64]                  8,192\n",
      "==========================================================================================\n",
      "Total params: 459,680\n",
      "Trainable params: 459,680\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 116.87\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 2048.00\n",
      "Params size (MB): 1.75\n",
      "Estimated Total Size (MB): 2052.75\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rsz = config.raster_image_size\n",
    "summary(model.D, (3, rsz, rsz));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_0.3",
   "language": "python",
   "name": "pytorch3d_0.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
