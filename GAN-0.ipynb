{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAN(\n",
       "  (generator): Generator(\n",
       "    (head): ConvBlock(\n",
       "      (conv): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (b1): GenBlock(\n",
       "      (mod_conv): ModulateConvBlock(\n",
       "        (style): DenseBlock(\n",
       "          (fc): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (activate): Identity()\n",
       "        )\n",
       "        (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (to_points): Conv2d(256, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (pool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
       "    )\n",
       "  )\n",
       "  (discriminator): Discriminator(\n",
       "    (model): Sequential(\n",
       "      (b0): ConvBlock(\n",
       "        (conv): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b1): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b2): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b3): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (linear): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (stylist): Stylist(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ReLU()\n",
       "      (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (13): ReLU()\n",
       "      (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (cont): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (renderer): MeshPointsRenderer(\n",
       "    (vrt_nrm): VertexNormals: size: 256 path: ./data/trimap_256.pth\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src.models.discriminator import Discriminator\n",
    "from src.models.generator import Generator\n",
    "from src.render.mesh_renderer import MeshPointsRenderer\n",
    "from src.models.stylist import Stylist\n",
    "\n",
    "class GAN(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.generator = Generator(hparams)\n",
    "        self.discriminator = Discriminator(hparams)\n",
    "        self.stylist = Stylist(hparams)\n",
    "        self.renderer = MeshPointsRenderer(hparams)        \n",
    "\n",
    "    def forward(self, points, style):        \n",
    "        \"\"\"\n",
    "        Generates a vertices using the generator\n",
    "        given input points & style\n",
    "        \"\"\"\n",
    "        return self.generator(points, style)\n",
    "    \n",
    "    def generator_step(self, points, images):\n",
    "        \"\"\"\n",
    "        Training step for generator\n",
    "        1. Sample random noise and labels\n",
    "        2. Pass noise and labels to generator to\n",
    "           generate images\n",
    "        3. Classify generated images using\n",
    "           the discriminator\n",
    "        4. Backprop loss\n",
    "        \"\"\"\n",
    "\n",
    "        # Sample random noise and labels\n",
    "\n",
    "        style = self.Stylist(images)\n",
    "        vertices = self(points, style)        \n",
    "        # Generate images\n",
    "        generated_imgs = self.renderer(vertices)\n",
    "\n",
    "        # Classify generated image using the discriminator\n",
    "\n",
    "        d_output = torch.squeeze(self.discriminator(generated_imgs, y))\n",
    "\n",
    "        # Backprop loss. We want to maximize the discriminator's\n",
    "        # loss, which is equivalent to minimizing the loss with the true\n",
    "        # labels flipped (i.e. y_true=1 for fake images). We do this\n",
    "        # as PyTorch can only minimize a function instead of maximizing\n",
    "        g_loss = nn.BCELoss()(d_output, torch.ones(x.shape[0],\n",
    "                              device=device))\n",
    "        self.log(\"loss/g_loss\", g_loss)\n",
    "        return g_loss\n",
    "    \n",
    "    def discriminator_step(self, points, images):\n",
    "        \"\"\"\n",
    "        Training step for discriminator\n",
    "        1. Get actual images and labels\n",
    "        2. Predict probabilities of actual images and get BCE loss\n",
    "        3. Get fake images from generator\n",
    "        4. Predict probabilities of fake images and get BCE loss\n",
    "        5. Combine loss from both and backprop\n",
    "        \"\"\"\n",
    "       \n",
    "        # Real images\n",
    "        d_output = torch.squeeze(self.discriminator(images))\n",
    "        loss_real = nn.BCELoss()(d_output, torch.ones(x.shape[0],\n",
    "                                 device=images.device))\n",
    "\n",
    "        # Fake images\n",
    "        style = self.Stylist(images)\n",
    "        vertices = self(points, style)        \n",
    "        \n",
    "        generated_imgs = self.renderer(vertices)\n",
    "        d_output = torch.squeeze(self.discriminator(generated_imgs))\n",
    "        loss_fake = nn.BCELoss()(d_output, torch.zeros(x.shape[0],\n",
    "                                 device=images.device))\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        self.log(\"loss/loss_real\", loss_real)\n",
    "        self.log(\"loss/loss_fake\", loss_fake)\n",
    "        self.log(\"loss/d_loss\", d_loss)\n",
    "        return d_loss\n",
    "    \n",
    "    def training_step(\n",
    "        self,\n",
    "        batch,\n",
    "        batch_idx,\n",
    "        optimizer_idx,\n",
    "        ):\n",
    "        images = batch['images']\n",
    "        points = batch['points']      \n",
    "        bs = img_patch.size(0)\n",
    "\n",
    "        # train generator\n",
    "        if optimizer_idx == 0:\n",
    "            loss = self.generator_step(points, images)\n",
    "\n",
    "        # train discriminator\n",
    "        if optimizer_idx == 1:\n",
    "            loss = self.discriminator_step(points, images)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        gsp = list(self.generator.parameters()) + list(self.stylist.parameters())\n",
    "        gs_optimizer = torch.optim.Adam(gsp,\n",
    "                lr=self.hparams.lr_gs)\n",
    "        d_optimizer = torch.optim.Adam(self.discriminator.parameters(),\n",
    "                lr=self.hparams.lr_d)\n",
    "        return ([gs_optimizer, d_optimizer], [])\n",
    "    \n",
    "    \n",
    "from src.config import get_parser\n",
    "config = get_parser().parse_args(args=[])\n",
    "#config.batch_size = 8\n",
    "model = GAN(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stylist(torch.rand(5, 1, 64, 64)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_0.3",
   "language": "python",
   "name": "pytorch3d_0.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
