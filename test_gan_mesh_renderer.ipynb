{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src.config import get_parser\n",
    "#from src.models.gan import GAN\n",
    "from src.callback.points_image import PointsImage\n",
    "from src.data.masked_datamodule import MaskedDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAN(\n",
       "  (G): Generator(\n",
       "    (head): ConvBlock(\n",
       "      (conv): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (body): Sequential(\n",
       "      (b1): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b2): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b3): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (tail): Sequential(\n",
       "      (0): Conv2d(256, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (D): Discriminator(\n",
       "    (model): Sequential(\n",
       "      (b0): ConvBlock(\n",
       "        (conv): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b1): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b2): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (b3): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (linear): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (R): MeshPointsRenderer(\n",
       "    (vrt_nrm): VertexNormals: size: 256 path: ./data/trimap_256.pth\n",
       "  )\n",
       "  (edge_loss): EdgeLoss()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.loss import ( \n",
    "    mesh_edge_loss, \n",
    "    mesh_laplacian_smoothing, \n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "\n",
    "from src.models.discriminator import Discriminator\n",
    "from src.models.generator import Generator\n",
    "from src.render.mesh_renderer import MeshPointsRenderer\n",
    "from src.loss.edge_loss import EdgeLoss\n",
    "from src.utilities.util import grid_to_list\n",
    "\n",
    "class GAN(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        self.automatic_optimization = False\n",
    "        self.mean = sum(hparams.image_mean) / len(hparams.image_mean)\n",
    "        self.std = sum(hparams.image_std) / len(hparams.image_std)\n",
    "        \n",
    "        self.G = Generator(hparams)\n",
    "        self.D = Discriminator(hparams)                \n",
    "        self.R = MeshPointsRenderer(hparams)     \n",
    "        self.edge_loss = EdgeLoss(hparams)\n",
    "        \n",
    "     \n",
    "    def forward(self, shape, style):\n",
    "        return self.G(shape, style)\n",
    "    \n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.mse_loss(y_hat, y)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):        \n",
    "        img_patch = batch['img_patch']\n",
    "        points = batch['points']        \n",
    "        pt_normals = batch['normals']\n",
    "        faces = batch['faces']\n",
    "        bs = img_patch.size(0)\n",
    "        pt_normals = pt_normals.reshape(bs, 3, -1).permute(0, 2, 1)        \n",
    "        self.R.setup(points.device)        \n",
    "        \n",
    "        # train generator\n",
    "        if optimizer_idx == 0:            \n",
    "            vertices = points + torch.randn_like(points) * self.hparams.G_noise_amp            \n",
    "            vertices = self.G(vertices)            \n",
    "            renders =  self.R(vertices).permute(0, 3, 1, 2)            \n",
    "            renders =  renders[ :, :3, :, :]            \n",
    "            renders = (renders - self.mean) / self.std                        \n",
    "            # ground truth result (ie: all fake)\n",
    "            # put on GPU because we created this tensor inside training_loop\n",
    "            valid = torch.ones(bs, 1).type_as(points)\n",
    "            \n",
    "            render_loss = self.adversarial_loss(self.D(renders), valid)\n",
    "            \n",
    "            #cos_sim = torch.cosine_similarity(normals, pt_normals, dim=-1)\n",
    "            #normal_consistency_loss = -(cos_sim.sum() / cos_sim.numel() - 1.)\n",
    "            \n",
    "            edge_loss = self.edge_loss(vertices)            \n",
    "            g_loss = render_loss + edge_loss * self.hparams.mesh_edge_loss_weight \\\n",
    "                + edge_loss * self.hparams.mesh_edge_loss_weight\n",
    "            #+ normal_consistency_loss * self.hparams.mesh_normal_consistency_weight\n",
    "            #tqdm_dict = {'g_loss': g_loss}\n",
    "            \n",
    "            self.log(\"loss/g_loss\", g_loss, on_epoch=True, prog_bar=True)\n",
    "            self.log(\"loss/render_loss\", render_loss, on_epoch=True)\n",
    "            self.log(\"loss/edge_loss\", edge_loss, on_epoch=True)\n",
    "            #self.log(\"loss/normal_consistency_loss\", normal_consistency_loss, on_epoch=True)\n",
    "            return OrderedDict({ 'loss': g_loss, })\n",
    "\n",
    "        # train discriminator\n",
    "        if optimizer_idx == 1:            \n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "\n",
    "            # how well can it label as real?\n",
    "            valid = torch.ones(bs, 1).type_as(points)         \n",
    "\n",
    "            real_loss = self.adversarial_loss(self.D(imgs), valid)\n",
    "\n",
    "            # how well can it label as fake?\n",
    "            fake = torch.zeros(imgs.size(0), 1).type_as(points)            \n",
    "                        \n",
    "            vertices = self.G(points)            \n",
    "            renders =  self.R(vertices).permute(0, 3, 1, 2)\n",
    "            renders =  renders[ :, :3, :, :]\n",
    "            renders = (renders - self.mean) / self.std            \n",
    "            fake_loss = self.adversarial_loss(\n",
    "                self.D(renders.detach()), fake)\n",
    "\n",
    "            # discriminator loss is the average of these\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            tqdm_dict = {'d_loss': d_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': d_loss,                \n",
    "            })\n",
    "            self.log(\"loss/d_loss\", d_loss, on_step=True, on_epoch=True, prog_bar=True)            \n",
    "            return output\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        lr_g = self.hparams.lr_g\n",
    "        lr_d = self.hparams.lr_d\n",
    "        b1 = self.hparams.beta1\n",
    "        b2 = self.hparams.beta2      \n",
    "        opt_g = torch.optim.Adam(self.G.parameters(), \n",
    "                                 lr=lr_g, betas=(b1, b2))\n",
    "        opt_d = torch.optim.Adam(self.D.parameters(), \n",
    "                                 lr=lr_d, betas=(b1, b2))\n",
    "        return [opt_g, opt_d], []\n",
    "    \n",
    "config = get_parser().parse_args(args=[])\n",
    "#config.batch_size = 8\n",
    "model = GAN(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.data.masked_datamodule.MaskedDataModule at 0x7faac294d490>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = MaskedDataModule(config)\n",
    "dm.setup()\n",
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | G         | Generator          | 1.8 M \n",
      "1 | D         | Discriminator      | 1.8 M \n",
      "2 | R         | MeshPointsRenderer | 0     \n",
      "3 | edge_loss | EdgeLoss           | 0     \n",
      "-------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.264    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33382cdad35d44ddbd13b7408d5a6ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "torch.Size([1, 65536, 3])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bobi/miniconda3/envs/pytorch3d/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bobi/miniconda3/envs/pytorch3d/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/bobi/miniconda3/envs/pytorch3d/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/bobi/miniconda3/envs/pytorch3d/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/bobi/miniconda3/envs/pytorch3d/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/bobi/miniconda3/envs/pytorch3d/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/bobi/miniconda3/envs/pytorch3d/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/bobi/miniconda3/envs/pytorch3d/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/bobi/miniconda3/envs/pytorch3d/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, max_epochs=5, progress_bar_refresh_rate=20\n",
    "#                      ,callbacks=[\n",
    "#                          #LogExportCallback(config),\n",
    "#                          PointsImage(config)\n",
    "#                          ]\n",
    "                    )\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-354eaa7f0702>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m65536\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvrt_nrm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "points = torch.randn([1, 65536, 3]).to(model.device)\n",
    "model.R.vrt_nrm(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VertexNormals: size: 256 path: ./data/trimap_256.pth"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.R.vrt_nrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VertexNormals: size: 256 path: ./data/trimap_256.pth"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utilities.vertex_normals import VertexNormals\n",
    "\n",
    "vrt_nrm = VertexNormals(config)\n",
    "vrt_nrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5674,  0.1096,  0.8161],\n",
       "         [-0.2778, -0.9243, -0.2618],\n",
       "         [-0.2253, -0.8276, -0.5141],\n",
       "         ...,\n",
       "         [ 0.0401,  0.3813, -0.9236],\n",
       "         [ 0.2087,  0.8959, -0.3921],\n",
       "         [ 0.3158, -0.5125, -0.7985]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vrt_nrm.vertex_normals_fast(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_0.3",
   "language": "python",
   "name": "pytorch3d_0.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
